---
title: "Respuestas a la tarea 1"
summary: " "
weight: 2
type: book
toc: false
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="respuestas" class="section level2">
<h2>Respuestas</h2>
</div>
<div id="pregunta-1" class="section level2">
<h2>Pregunta 1</h2>
<p>Suponga que está interesado en una variable aleatoria que tiene una distribución Bernoulli con parámetro <span class="math inline">\(p\)</span>. La función de densidad está definida como:</p>
<p><span class="math display">\[f(x_;p)=\left\{\begin{array} .1 &amp; \text{con probabilidad } p \\ 0 &amp; \text{con probabilidad } 1-p \end{array} \right.\]</span>
Suponga que tiene una muestra de <span class="math inline">\(N\)</span> observaciones independientes e idénticamente distribuidas.</p>
<ol style="list-style-type: lower-alpha">
<li><p>[2 puntos] Plantee la función de log verosimilitud del problema.</p>
<p><em>Noten que podemos escribir la función de densidad para la <span class="math inline">\(i\)</span>-ésima observación como</em> <span class="math display">\[f(x_i;p)=p^{x_i}(1-p)^{(1-x_i)}\]</span></p>
<p><em>Por tanto, la función de verosimilitud es</em></p>
<p><span class="math display">\[L_N(p)=\prod_{i=1}^N f(x;p)=\prod_{i=1}^N p^{x_i}(1-p)^{(1-x_i)} = p^{\sum_{i=1}^N x_i}(1-p)^{N-\sum_{i=1}^N x_i}\]</span></p>
<p><em>Y la función de log verosimilitud será:</em></p>
<p><span class="math display">\[\mathcal{L_N(p)}=\ln{L_N(p)}=\sum x_i \ln(p)-(N-\sum x_i)\ln(1-p)\]</span></p></li>
<li><p>[3 puntos] Obtenga las condiciones de primer orden y resuelva para <span class="math inline">\(\hat{p}\)</span>.</p>
<p><em>Derivando <span class="math inline">\(\mathcal{L}_N\)</span> con respecto a <span class="math inline">\(p\)</span> obtenemos la condición de primer orden</em>:</p>
<p><span class="math display">\[\frac{d\mathcal{L}_N(p)}{d p}=\frac{\sum x_i}{p}-\frac{n-\sum x_i}{1-p}=0\]</span></p>
<p><em>Y resolviendo, obtenemos el estimador de máxima verosimilitud <span class="math display">\[\hat{p}_{MV}=\bar{x}\]</span> es decir, la media muestral</em></p></li>
<li><p>[3 puntos] ¿Cuál es la media y la varianza del estimador de máxima verosimilitud que ha encontrado?</p>
<p><em>Obtenemos directamente la esperanza</em> <span class="math display">\[E(\hat{p}_{MV})=E(\bar{x})=\frac{1}{N}E\left(\sum x_i\right)=\frac{1}{n}n p=p\]</span></p>
<p><em>Mientras que la varianza es</em> <span class="math display">\[V(\hat{p}_{MV})=\frac{1}{N^2}V\left(\sum x_i\right)=\frac{p(1-p)}{n}\]</span></p></li>
</ol>
</div>
<div id="pregunta-2" class="section level2">
<h2>Pregunta 2</h2>
<p>Considere el modelo logit:</p>
<p><span class="math display">\[f(y_i|x_i;\theta_0)=\left\{ \begin{array} .1 &amp; \frac{\exp\{x_i&#39;\theta_0\}}{1+\exp\{x_i&#39;\theta_0\}}  \\ 0 &amp;  \frac{1}{1+\exp\{x_i&#39;\theta_0\}} \end{array} \right.\]</span>
donde <span class="math inline">\(x_i\)</span> es un vector de variables explicativas, <span class="math inline">\(\theta_0\)</span> y es el vector de parámetros poblacional. Asuma que dispone de observaciones <span class="math inline">\((y_i,x_i)\)</span> que son iid.</p>
<ol style="list-style-type: lower-alpha">
<li><p>[3 puntos] Escriba la función de log verosimilitud condicional para la observación <span class="math inline">\(i\)</span>.</p>
<p><em>Es conveniente escribir el problema en término de <span class="math inline">\(\Lambda (x_i&#39;\theta_0) \equiv \frac{\exp\{x_i&#39;\theta_0\}}{1+\exp\{x_i&#39;\theta_0\}}\)</span>. Así, la función de verosimilitud para la observación <span class="math inline">\(i\)</span> es:</em></p>
<p><span class="math display">\[f(y_i|x_i;\theta_0)=\Lambda (x_i&#39;\theta_0)^{y_i}(1-\Lambda (x_i&#39;\theta_0))^{(1-y_i)}\]</span></p>
<p><em>Tomando logs, la función de log verosimilitud es:</em></p>
<p><span class="math display">\[\mathcal{l}(y_i|x_i,\theta)=\ln f(y_i|x_i;\theta)=y_i\ln \Lambda (x_i&#39;\theta)+(1-y_i)(1-\Lambda (x_i&#39;\theta))\]</span></p></li>
<li><p>[4 puntos] Encuentre el vector score para la observación <span class="math inline">\(i\)</span>.</p>
<p><em>El vector score es el vector de primeras derivadas parciales de la log verosimilitud. Un pequeño truco facilita las cosas. Se puede mostrar que <span class="math inline">\(\Lambda (\cdot)&#39;=\Lambda (\cdot)(1-\Lambda (\cdot))\)</span>. Entonces:</em></p>
<p><span class="math display">\[\frac{\partial \mathcal{l}_i}{\partial\theta}=y_i \frac{1}{\Lambda (x_i&#39;\theta)}\Lambda (x_i&#39;\theta)(1-\Lambda (x_i&#39;\theta))x_i+(1-y_i)\frac{1}{1-\Lambda (x_i&#39;\theta)}\Lambda (x_i&#39;\theta)(1-\Lambda (x_i&#39;\theta))x_i\]</span></p>
<p><em>Simplificando:</em></p>
<p><span class="math display">\[\frac{\partial \mathcal{l}_i}{\partial\theta}=(y_i-\Lambda (x_i&#39;\theta))x_i \equiv s(y_i,x_i;\theta)\]</span></p></li>
<li><p>[4 puntos] Encuentre la hesiana de la función de log verosimilitud con respecto a <span class="math inline">\(\mathbf{\theta}\)</span>.</p>
<p><em>Procedemos a derivar el score con respecto a <span class="math inline">\(\theta&#39;\)</span></em>:</p>
<p><span class="math display">\[H(y_i,x_i;\theta)\equiv \frac{\partial s(y_i,x_i;\theta)}{\partial \theta&#39;}= -\Lambda(x_i&#39;\theta)(1-\Lambda(x_i&#39;\theta))x_ix_i&#39;\]</span></p></li>
<li><p>[3 puntos] Obtenga la matriz de información para la observación <span class="math inline">\(i\)</span>.</p>
<p><em>La matriz de información es <span class="math inline">\(E(s(y_i,x_i;\theta_0)s(y_i,x_i;\theta_0)&#39;|x_i)\)</span></em></p>
<p><span class="math display">\[I(\theta_0)=E((y_i-\Lambda(x_i&#39;\theta_0))^2x_ix_i&#39;)\]</span></p></li>
</ol>
</div>
<div id="pregunta-3" class="section level2">
<h2>Pregunta 3</h2>
<p>Suponga una variable aleatoria <span class="math inline">\(X_i\)</span> con distribución desconocida. Sin embargo, sí conocemos que <span class="math inline">\(E(X)=\mu=58\)</span> y que <span class="math inline">\(\sqrt{V(X)}=\sigma=10\)</span>. Suponga que se recolecta una muestra de 50 observaciones.</p>
<ol style="list-style-type: lower-alpha">
<li><p>[1 punto] ¿Cuál es la distribución asintótica de la media muestral <span class="math inline">\(\bar{X}\)</span>?</p>
<p><em>Si se puede aplicar un teorema de límite central a la media muestral, sabemos que la nueva variable hereda la media de <span class="math inline">\(X_i\)</span> y la desviación estándar es la desviación estándar de <span class="math inline">\(X_i\)</span> dividida por la raíz del tamaño de la muestra. Es decir</em>: <span class="math display">\[\bar{X}\sim \mathcal{N}(58,10/\sqrt{50})\]</span></p></li>
<li><p>[2 punto] ¿Cuál es la probabilidad de que <span class="math inline">\(\bar{X}&gt;60\)</span>?</p>
<p><em>Sabemos que <span class="math inline">\(\frac{\bar{X}-58}{10/\sqrt{50}}\sim\mathcal{N}(0,1)\)</span>, por tanto</em>: <span class="math display">\[P(\bar{X}&gt;60)=P\left(z&gt;\frac{60-58}{10/\sqrt{50}}\right)=P(z&gt;1.414214)=1-\Phi(1.414214)\]</span> <em>La probabilidad es de 7.86%.</em>:</p>
<pre class="r"><code>   1-pnorm((60-58)/(10/sqrt(50)))</code></pre>
<pre><code>## [1] 0.0786496</code></pre></li>
<li><p>[1 punto] ¿Cuál es la probabilidad de que una observación elegida al azar sea tal que <span class="math inline">\(X_i&lt;50\)</span>?</p>
<p><em>Es imposible de determinar porque no sabemos la distribución de <span class="math inline">\(X_i\)</span>. Esto es algo muy bueno de los TLC, pues nos permiten decir cosas sobre la media muestral sin saber la distribución de la que provienen las observaciones. Solo necesitamos que se cumplan las condiciones sobre las <span class="math inline">\(X_i\)</span> para aplicar los TLC.</em></p></li>
<li><p>[1 punto] Provea un intervalo de confianza de 90% para la media muestral.</p>
<p><em>Por un lado, sabemos que <span class="math inline">\(Z=\frac{\bar{X}-\mu}{\sigma/\sqrt{N}}\sim \mathcal{N}(0,1)\)</span>. Por otro lado, queremos obtener <span class="math inline">\(P(-z_{\alpha/2}&lt;Z&lt;z_{\alpha_2})=0.90\)</span>. Manipulando, obtenemos una expresión para el intervalo de confianza:</em> <span class="math display">\[\left(\bar{X}-z_{\alpha/2}\frac{\sigma}{\sqrt{N}},\bar{X}+z_{\alpha/2}\frac{\sigma}{\sqrt{N}}\right)\]</span></p>
<p><em>En nuestro caso, el intervalo es</em>: <span class="math display">\[P\left(\bar{X}\pm 1.6448(10/\sqrt{50})\right)=0.90\]</span> <em>donde obtenemos el 1.6648 como</em></p>
<pre class="r"><code>qnorm(0.95)</code></pre>
<pre><code>## [1] 1.644854</code></pre>
<p><em>Entonces, el intervalo de confianza es</em>: <span class="math display">\[P(\bar{X}\pm 2.3261)=0.90\]</span></p></li>
</ol>
</div>
<div id="pregunta-4" class="section level2">
<h2>Pregunta 4</h2>
<p>Sea <span class="math inline">\(x_1\)</span> un vector de variables continuas, <span class="math inline">\(x_2\)</span> una variable continua y <span class="math inline">\(d_1\)</span> una variable dicotómica. Considere el siguiente modelo probit:
<span class="math display">\[P(y=1│x_1,x_2 )=\Phi(x_1&#39;\alpha+\beta x_2+\gamma x_2^2 )\]</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>[2 punto] Provea una expresión para el efecto marginal de <span class="math inline">\(x_2\)</span> en la probabilidad. ¿Cómo estimaría este efecto marginal?</p>
<p><em>El efecto marginal de interés es</em>: <span class="math display">\[\frac{\partial P(y=1|x_1,x_2)}{\partial x_2}=\phi(x_1\alpha+\beta x_2+\gamma x_2^2)(\beta+2\gamma x_2)\]</span> <em>Para estimarlo, usamos un modelo probit para obtener estimadores consistentes de <span class="math inline">\(\alpha\)</span>, <span class="math inline">\(\beta\)</span> y <span class="math inline">\(\gamma\)</span> y empleamos software para evaluar valores relevantes de <span class="math inline">\(x_1\)</span> y <span class="math inline">\(x_2\)</span> (por ejemplo, los promedios) en la función de distribución <span class="math inline">\(\phi\)</span>.</em></p></li>
<li><p>[2 punto] Considere ahora el modelo:
<span class="math display">\[P(y=1│x_1  ,x_2 ,d_1)=\Phi(x_1 &#39;\delta+\pi x_2+\rho d_1+\nu x_2 d_1 )\]</span>
Provea la nueva expresión para el efecto marginal de <span class="math inline">\(x_2\)</span>.</p>
<p><em>El efecto marginal es:</em> <span class="math display">\[\frac{\partial P(y=1|x_1,x_2)}{\partial x_2}=\phi(x_1\delta+\pi x_2+\rho d_1+  \nu x_2d_1)(\pi+\nu d_1)\]</span></p></li>
<li><p>[2 punto] En el modelo de la parte b., ¿cómo evaluaría el efecto de un cambio en <span class="math inline">\(d_1\)</span> en la probabilidad? Provea una expresión para este efecto.</p>
<p><em>Dado que <span class="math inline">\(d_1\)</span> es una variable dicotómica, el efecto de <span class="math inline">\(d_1\)</span> se mide como la diferencia en probabilidad cuando <span class="math inline">\(d_1=1\)</span> y cuando <span class="math inline">\(d_1=0\)</span></em>: <span class="math display">\[P(y=1|x_1,x_2,d_1=1)-P(y=1|x_1,x_2,d_1=0)=\phi(x_1\delta+(\pi+\nu)x_2+\rho)-\phi(x_1\delta+\pi x_2)\]</span></p></li>
</ol>
</div>
<div id="pregunta-5" class="section level2">
<h2>Pregunta 5</h2>
<p>Considere el modelo Poisson visto en clase y un vector de variables explicativas <span class="math inline">\(x\)</span>, todas continuas, usadas para parametrizar la media.</p>
<ol style="list-style-type: lower-alpha">
<li><p>[1 puntos] ¿Cuál es el efecto de un cambio en el <span class="math inline">\(j\)</span>ésimo regresor sobre <span class="math inline">\(E(y│x)\)</span>?</p>
<p><em>Con un modelo Poisson parametrizamos la media como <span class="math inline">\(\mu=exp(x&#39;\beta)\)</span>. En este caso, un cabio en un regresor <span class="math inline">\(j\)</span> tiene el efecto:</em></p>
<p><span class="math display">\[\frac{\partial E(y|x)}{\partial x_j}=\beta_j exp(x&#39;\beta)\]</span></p>
<p><em>Es decir, un cambio en una unidad de <span class="math inline">\(x_j\)</span> produce un cambio en el conteo esperado de <span class="math inline">\(y\)</span> igual a <span class="math inline">\(\beta_j exp(x&#39;\beta)\)</span> unidades.</em></p></li>
<li><p>[2 puntos] Usando esta expresión, muestre que si el <span class="math inline">\(j\)</span>ésimo regresor es <span class="math inline">\(x_j\)</span>, entonces <span class="math inline">\(100 \beta_j\)</span> es la semielasticidad de <span class="math inline">\(E(y│x)\)</span> con respecto a <span class="math inline">\(x_j\)</span>. Nota: Este punto es muy útil para la interpretación de los coeficientes de un modelo Poisson.</p>
<p><em>Resolviendo para <span class="math inline">\(\beta_j\)</span> en la expresión que acabamos de encontrar</em>: <span class="math display">\[\beta_j=\frac{\partial E(y|x)}{\partial x_j}\frac{1}{\exp(x&#39;\beta)}=\frac{\partial E(y|x)}{\partial x_j}\frac{1}{E(y|x)}=\frac{\partial\ln E(y|x)}{\partial x_j}\]</span></p>
<p><span class="math inline">\(\frac{\partial\ln E(y|x)}{\partial x_j}\)</span> <em>es una semileasticidad, es decirm un cambio marginal de <span class="math inline">\(x_j\)</span> se asocia con un cambio porcentual en la media condicional igual a</em> <span class="math inline">\(100\beta_j\Delta x_j\)</span>.</p></li>
<li><p>[2 puntos] ¿Cómo se interpreta <span class="math inline">\(\beta_j\)</span> si reemplazamos <span class="math inline">\(x_j\)</span> por <span class="math inline">\(\log(x_j)\)</span>)?</p>
<p><em>Si ahora el regresor de interés entra en el índice como un logaritmo</em>: <span class="math display">\[\beta_j=\frac{\partial E(y|x)}{\partial x_j}\frac{x_j}{E(y|x)}\]</span> <em>la defnición de una elasticidad.</em></p></li>
</ol>
</div>
<div id="pregunta-6-cameron-trivedi-2005" class="section level2">
<h2>Pregunta 6 (Cameron &amp; Trivedi, 2005)</h2>
<p>En esta pregunta comparará el estimador de MCO, de MV y de MCNL. Antes de comenzar, recuerde fijar una semilla en R (o el software que utilice) para poder replicar sus cálculos. Se recomienda repasar la sección 5.9 en CT.</p>
<p>Cameron y Trivedi proveen pistas para replicar esta tabla <a href="http://cameron.econ.ucdavis.edu/mmabook/mma05p1mle.do">aquí</a> y <a href="http://cameron.econ.ucdavis.edu/mmabook/mma05p2nls.do">aquí</a>, aunque ellos trabajan en Stata. La idea es entender la <em>anatomía</em> de los distintos estimadores estudiados en clase.</p>
<ol style="list-style-type: lower-alpha">
<li>[2 puntos] Genere una muestra de 10,000 observaciones llamadas <span class="math inline">\(x\)</span> tales que <span class="math inline">\(x\sim\mathcal{N}(1,1)\)</span>. Posteriormente, genere <span class="math inline">\(\lambda=exp(\beta_1+\beta_2x)\)</span>, donde <span class="math inline">\((\beta_1\;\beta_2)=(2\;-1)\)</span>. Finalmente, genere <span class="math inline">\(y|\mathbf{x} \sim exponencial(\lambda)\)</span>. Es decir, el proceso generador de datos es: <span class="math display">\[\begin{aligned}y|\mathbf{x} \sim exponencial(\lambda) \\ \lambda=exp(\beta_1+\beta_2x)\end{aligned} \]</span> Note que <span class="math inline">\(1/\lambda\)</span> es conocida como la tasa en la distribución exponencial. En R, <em>rexp</em> requiere especificar como parámetro a la tasa en lugar de <span class="math inline">\(\lambda\)</span>.</li>
</ol>
<p><span class="math display">\[
\begin{aligned}
y|\mathbf{x} \sim exponencial(\lambda) \\
\lambda=exp(\beta_1+\beta_2x)
\end{aligned}
\]</span></p>
<pre><code>```r
set.seed(820)
# Here a = 2, b = -1 and x ~ N[1, 1]
a &lt;- 2
b &lt;- -1
mux &lt;- 1
sigx &lt;- 1
obs &lt;- 10000


x &lt;- rnorm(obs, mux, sigx)
lambda &lt;- exp(a + b * x)
Ey = 1/lambda

# Generar y
y &lt;- (1/lambda) * rexp(1/lambda)
```</code></pre>
<ol style="list-style-type: lower-alpha">
<li><p>[2 puntos] Reporte una tabla con la media, la desviación estándar, el mínimo y el máximo de <span class="math inline">\(x\)</span>, <span class="math inline">\(\lambda\)</span> y <span class="math inline">\(y\)</span>.</p>
<p><em>Aquí usé la función stat.desc de la librería pastecs:</em></p>
<pre class="r"><code># Obtener descriptiva
descriptiva &lt;- cbind(x, lambda, y)
stat.desc(descriptiva)
##                          x       lambda            y
## nbr.val       1.000000e+04 1.000000e+04 1.000000e+04
## nbr.null      0.000000e+00 0.000000e+00 0.000000e+00
## nbr.na        0.000000e+00 0.000000e+00 0.000000e+00
## min          -2.651393e+00 5.846575e-02 3.372353e-05
## max           4.839314e+00 1.047308e+02 2.406148e+01
## range         7.490707e+00 1.046723e+02 2.406144e+01
## sum           9.939838e+03 4.509838e+04 5.947033e+03
## median        9.937037e-01 2.735451e+00 2.357482e-01
## mean          9.939838e-01 4.509838e+00 5.947033e-01
## SE.mean       1.001648e-02 5.893218e-02 1.159207e-02
## CI.mean.0.95  1.963431e-02 1.155189e-01 2.272278e-02
## var           1.003298e+00 3.473002e+01 1.343760e+00
## std.dev       1.001648e+00 5.893218e+00 1.159207e+00
## coef.var      1.007710e+00 1.306747e+00 1.949219e+00</code></pre></li>
<li><p>[2 puntos] Reporte una gráfica donde muestre la relación entre <span class="math inline">\(x\)</span> y <span class="math inline">\(\lambda\)</span> en el plano <span class="math inline">\((x,\lambda)\)</span>. Realice otra gráfica similar, ahora para <span class="math inline">\((x,1/\lambda)\)</span>.</p>
<p><em><span class="math inline">\(\lambda\)</span> es decreciente en <span class="math inline">\(x\)</span></em>:</p>
<pre class="r"><code>plot(x, lambda)</code></pre>
<p><img src="/tareas/tarea_1/tarea1_respuestas_files/figure-html/unnamed-chunk-5-1.png" width="672" />
<em>por lo que <span class="math inline">\(1/\lambda\)</span> es creciente en <span class="math inline">\(x\)</span>:</em></p>
<pre class="r"><code># Obtener descriptiva
plot(x, Ey)</code></pre>
<p><img src="/tareas/tarea_1/tarea1_respuestas_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p></li>
<li><p>[2 puntos] Estime por MCO una regresión entre <span class="math inline">\(y\)</span> y <span class="math inline">\(x\)</span>. Deberá obtener coeficientes parecidos a los de la primera columna de la Tabla 5.7 en CT.</p>
<p><em>Estimando por MCO y obteniendo los errores que asumen homocedasticidad:</em></p>
<pre class="r"><code>obs &lt;- 10000
X &lt;- cbind(rep(1, 10000), x)

## MCO
b_mco &lt;- solve(t(X) %*% X) %*% t(X) %*% y
b_mco
##         [,1]
##   0.01936736
## x 0.57881822

## MCO, errores de mínimos cuadrados
uhat_mco &lt;- y - b_mco[1] - b_mco[2] * x
s2_mco &lt;- as.numeric(t(uhat_mco) %*% uhat_mco/(obs - 2))

V_mco &lt;- s2_mco * solve(t(X) %*% X)
sqrt(diag(V_mco)) * obs/(obs - 2)
##                     x 
## 0.01414563 0.01002455</code></pre></li>
<li><p>[1 punto] ¿Por qué difieren los coeficientes que obtuvo y los que se presentan en la Tabla 5.7 de CT?</p>
<p><em>Los errores son distintos a los presentados en la tabla del libro porque la muestra con la que trabajamos es distinta. Aunque el proceso generador de datos es el mismo, la muestra que tenemos a la mano es una realización de dicho proces.</em></p></li>
<li><p>[2 puntos] Obtenga los errores robustos. En R, una librería que será muy útil es <em>sandwich</em>.</p>
<pre class="r"><code>## MCO, errores de White se puede obtener como un caso particular de la ecuación
## 5.77 en CT
Omegahat_White &lt;- diag(uhat_mco^2)
V_mco_White &lt;- solve(t(X) %*% X) %*% t(X) %*% Omegahat_White %*% X %*% solve(t(X) %*% 
    X)
sqrt(diag(V_mco_White)) * obs/(obs - 2)
##                     x 
## 0.01347206 0.02073000</code></pre>
<p><em>La función vcoHC calcula los errores robustos. HC significa heterocedasticity consistent. Una búsqueda rápida en ?vcovHC permite saber que type = “HC0” o, equivalentemente, type = “HC”, produce los errores de White.</em></p>
<pre class="r"><code>mco_lm &lt;- lm(y ~ x)
sqrt(diag(vcovHC(mco_lm, type = &quot;HC0&quot;)))
## (Intercept)           x 
##  0.01346937  0.02072586
sqrt(diag(vcovHC(mco_lm, type = &quot;HC&quot;)))
## (Intercept)           x 
##  0.01346937  0.02072586</code></pre></li>
<li><p>[1 punto] ¿El estimador de MCO es consistente? ¿Por qué?</p>
<p><em>El estimador de MCO claramente no es consistente. Sabemos que <span class="math inline">\(\beta_1=2\)</span> y que <span class="math inline">\(\beta_2=-1\)</span>, sin embargo, los coeficientes estimados están muy lejos de los parámetros del proceso generador de datos.</em></p></li>
<li><p>[2 puntos] Plantee la función de log verosimilitud.</p>
<p><em>En el proceso generador de datos propuesto, la densidad es <span class="math inline">\(f(\theta)=\lambda exp(-y\lambda)\)</span>, donde parametrizamos <span class="math inline">\(\lambda=exp(\beta_1+\beta_2x)\)</span>. Por tanto <span class="math inline">\(\ln f(\lambda)=\ln(\lambda)-y\lambda\)</span>. Y la función de log verosimilitud será</em>:</p>
<p><span class="math display">\[\mathcal{L}_N(\beta_1,\beta_2)=\sum_i \left(
(\beta_1+\beta_2 x_i)-y_i exp(\beta_1+\beta_2 x_i)\right)\]</span></p></li>
<li><p>[4 puntos] Obtenga el estimador de máxima verosimilitud de <span class="math inline">\(\beta_1\)</span> y <span class="math inline">\(\beta_2\)</span> obteniendo la solución al negativo del problema de log verosimilitud. En R, puede emplear, por ejemplo <em>nlm</em>.</p>
<pre class="r"><code># MV
fn &lt;- function(theta) {
    sum(-(theta[1] + theta[2] * x) + (y * exp(theta[1] + theta[2] * x)))
}
res_mv &lt;- nlm(fn, theta &lt;- c(0.1, -0.1), hessian = TRUE)
res_mv$estimate
## [1]  2.012268 -1.008822

# Errores asumiendo igualdad de la matriz de información, es decir, errores no
# robustos (no pedido en el problema). Son los errores entre () en la tabla
A &lt;- res_mv$hessian
V_mv &lt;- solve(A)
sqrt(diag(V_mv))
## [1] 0.01424297 0.01020450

# Vean que si calculamos B
index_mv &lt;- X %*% t(t(res_mv$estimate))

# El score es
s &lt;- matrix(c(1 - y * exp(index_mv), x - y * x * exp(index_mv)), ncol = 2)
B &lt;- t(s) %*% s
V_mv_B &lt;- solve(B)
sqrt(diag(V_mv_B))
## [1] 0.01467047 0.01053934

# Esto es la igualdad de la matriz de información en acción</code></pre></li>
<li><p>[3 puntos] Usando la matriz hesiana obtenida en la solución del problema de optimización, encuentre los errores estándar robustos de los coeficientes estimados.</p>
<pre class="r"><code># Varianza de sándwich apenas cambia el estimador
V_mv_White &lt;- solve(A) %*% B %*% solve(A)
sqrt(diag(V_mv_White))
## [1] 0.013838404 0.009885757</code></pre></li>
<li><p>[4 puntos] El modelo antes descrito puede expresarse como una regresión no lineal de la forma <span class="math inline">\(y=exp(-x&#39;\beta)+u\)</span>. Encuentre la solución para <span class="math inline">\(\beta_1\)</span> y <span class="math inline">\(\beta_2\)</span>. Reporte los errores estándar no robustos. ¿Son consistentes estos errores? ¿Por qué?</p>
<pre class="r"><code># MCNL
res_mcnl &lt;- nls(y ~ exp(-beta1 - beta2 * x))
summary(res_mcnl)$coef
##        Estimate  Std. Error   t value Pr(&gt;|t|)
## beta1  1.784506 0.029080213  61.36494        0
## beta2 -0.893747 0.009567403 -93.41584        0

# Calculamos el índice ajustado
index_mcnl &lt;- -summary(res_mcnl)$coef[1] - summary(res_mcnl)$coef[2] * x
yhat &lt;- exp(index_mcnl)
uhat2 &lt;- (y - yhat)^2</code></pre>
<p><em>Estos errores asumen una varianza homocedástica. Sin embargo, sabemos de del proceso generador de datos que la varianza de una variable aleatoria con que se distribuye exponencial será <span class="math inline">\(\lambda^2\)</span>. Es decir, por construcción el proceso simulado sufre de heterocedasticidad, por lo que el estimador de la varianza de <span class="math inline">\(\hat{\theta}\)</span> es inconsistente.</em></p></li>
<li><p>[3 puntos] Ahora implementará la matriz de varianzas y covarianzas robusta en la ecuación 5.81 de CT. Dé una expresión para <span class="math inline">\(\hat{D}\)</span> en este problema.</p>
<p><em>En este problema <span class="math inline">\(g(x_i,\beta)=exp(-x&#39;\beta)\)</span>. Por tanto</em>: <span class="math display">\[D=\partial g/\partial \beta&#39;=exp(-x&#39;\beta)x\]</span> <em>Y un estimador será: <span class="math display">\[\hat{D}=exp(-x&#39;\hat{\beta}_{MCNL})x\]</span></em></p></li>
<li><p>[3 puntos] Calcule el error estándar robusto definido como en la ecuación 5.81. En este caso <span class="math inline">\(\hat{\Omega}=Diag(\hat{u}_i^2)\)</span>.</p>
<pre class="r"><code># Calculamos el índice ajustado
index_mcnl &lt;- -summary(res_mcnl)$coef[1] - summary(res_mcnl)$coef[2] * x
yhat &lt;- exp(index_mcnl)
uhat2 &lt;- (y - yhat)^2

# MCNL robusta
Omegahat &lt;- diag(as.vector(uhat2))

# El vector de derivadas
d = cbind(yhat, yhat * x)

# Construimos la matriz de varianzas
V &lt;- solve(t(d) %*% d) %*% t(d) %*% Omegahat %*% d %*% solve(t(d) %*% d)

# Noten que hay que multiplicar por N/(N-k)
sqrt(diag(V)) * obs/(obs - 2)
##       yhat            
## 0.08733068 0.03979590</code></pre></li>
<li><p>[3 puntos] Calcule una versión alternativa de errores estándar (entre corchetes en Tabla 5.7), esta vez con <span class="math inline">\(\hat{\Omega}=Diag((exp(-x_i&#39;\beta))^2)\)</span>.</p>
<pre class="r"><code># MCNL, error robusto {}
Omegahat_alt &lt;- diag(as.vector(yhat^2))
V &lt;- solve(t(d) %*% d) %*% t(d) %*% Omegahat_alt %*% d %*% solve(t(d) %*% d)
sqrt(diag(V))
##       yhat            
## 0.14489245 0.06479738</code></pre></li>
<li><p>[1 puntos] En este experimento, ¿qué estimador tiene las mejores propiedades?</p>
<p><em>El estimador de MCO es inconsistente, mientras que el de MV y de MCNL son consistentes. Los errores no robustos de MCNL son inconsistentes dada la construcción del proceso generador de datos. Usando errores robustos, el estimador de MV es el más eficiente entre los estimadores consistentes.</em></p></li>
</ol>
</div>
<div id="pregunta-7" class="section level2">
<h2>Pregunta 7</h2>
<p>Use la base <em>grogger.csv</em> para esta pregunta. Esta base contiene información sobre arrestos y características socioeconómicas de individuos arrestados.</p>
<ol style="list-style-type: lower-alpha">
<li><p>[1 punto] Estime un modelo de probabilidad lineal que relacione <strong>arr86</strong> (haber si arrestado al menos una vez en 1986) con <strong>pcnv</strong>, <strong>avgsen</strong>, <strong>tottime</strong>, <strong>ptime86</strong>, <strong>inc86</strong>, <strong>black</strong>, <strong>hispan</strong> y <strong>born60</strong>. Reporte los errores que asumen homocedasticidad y los errores robustos a heteroscedasticidad.</p>
<pre class="r"><code>data.grogger &lt;- read_csv(&quot;./grogger.csv&quot;, locale = locale(encoding = &quot;latin1&quot;)) %&gt;% 
    clean_names()

# 7a. Modelo lineal
prob_lineal &lt;- lm(arr86 ~ pcnv + avgsen + tottime + ptime86 + inc86 + black + hispan + 
    born60, data = data.grogger)

# Errores homocedásticos
summary(prob_lineal)$coef
##                 Estimate   Std. Error    t value      Pr(&gt;|t|)
## (Intercept)  0.360983141 0.0160926665 22.4315306 2.222421e-102
## pcnv        -0.154380197 0.0209335584 -7.3747709  2.175031e-13
## avgsen       0.003502398 0.0063416742  0.5522829  5.808000e-01
## tottime     -0.002061300 0.0048883942 -0.4216721  6.732977e-01
## ptime86     -0.021595259 0.0044679175 -4.8334058  1.416871e-06
## inc86       -0.001224843 0.0001269505 -9.6481962  1.109628e-21
## black        0.161718283 0.0235044117  6.8803374  7.384637e-12
## hispan       0.089258629 0.0205591809  4.3415460  1.466620e-05
## born60       0.002869817 0.0171986431  0.1668630  8.674903e-01

# Errores robustos
lmtest::coeftest(prob_lineal, vcov = vcovHC(prob_lineal, &quot;HC&quot;))
## 
## t test of coefficients:
## 
##                Estimate  Std. Error  t value  Pr(&gt;|t|)    
## (Intercept)  0.36098314  0.01668044  21.6411 &lt; 2.2e-16 ***
## pcnv        -0.15438020  0.01893269  -8.1542 5.311e-16 ***
## avgsen       0.00350240  0.00587790   0.5959    0.5513    
## tottime     -0.00206130  0.00421859  -0.4886    0.6251    
## ptime86     -0.02159526  0.00274863  -7.8567 5.633e-15 ***
## inc86       -0.00122484  0.00011395 -10.7487 &lt; 2.2e-16 ***
## black        0.16171828  0.02548569   6.3455 2.590e-10 ***
## hispan       0.08925863  0.02103411   4.2435 2.274e-05 ***
## born60       0.00286982  0.01713126   0.1675    0.8670    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre></li>
<li><p>[2 punto] ¿Cuál es el efecto en la probabilidad de arresto si <strong>pcnv</strong> pasa de 0.5 a 0.75?</p>
<p><em>Como estamos estimando un modelo lineal, el efecto marginal es el mismo a lo largo de toda la curva de regresión. Para obtener el efecto deseado, basta multiplicar el coeficiente estimado para pcnv por la magnitud del cambio:</em></p>
<pre class="r"><code>prob_lineal$coef[2] * 0.25
##        pcnv 
## -0.03859505</code></pre></li>
<li><p>[2 punto] Realice una prueba de significancia conjunta de <strong>avgsen</strong>, <strong>tottime</strong> y <strong>born60 </strong>. ¿Qué concluye?</p>
<p><em>Aquí usé linearHypothesis de la librería car:</em></p>
<pre class="r"><code>car::linearHypothesis(prob_lineal, c(&quot;avgsen=0&quot;, &quot;tottime=0&quot;, &quot;born60=0&quot;))
## Linear hypothesis test
## 
## Hypothesis:
## avgsen = 0
## tottime = 0
## born60 = 0
## 
## Model 1: restricted model
## Model 2: arr86 ~ pcnv + avgsen + tottime + ptime86 + inc86 + black + hispan + 
##     born60
## 
##   Res.Df    RSS Df Sum of Sq      F Pr(&gt;F)
## 1   2719 500.92                           
## 2   2716 500.84  3  0.071308 0.1289  0.943</code></pre>
<p><em>La hipótesis nula <span class="math inline">\(H_0\)</span> es que ambos coeficientes son iguales a cero. El valor del estadístico F es pequeño (0.1289), con un valor <span class="math inline">\(p\)</span> de 0.94, por lo que no se rechaza la <span class="math inline">\(H_0\)</span>.</em></p></li>
<li><p>[2 punto] Estime un modelo probit relacionando las mismas variables. ¿Cuál es el efecto en la probabilidad de arresto cuando <strong>pcnv</strong> pasa de 0.50 a 0.75, evaluando el cambio en los valores promedio de <strong>avgsen</strong>, <strong>tottime</strong>, <strong>inc86</strong> y <strong>ptime86</strong> y cuando los individuos son de raza negra, no hispánicos y nacidos en 1960 (<strong>born60</strong> igual a 1). ¿Cómo se comparan estos resultados con lo que encontró con el modelo de probabilidad lineal?</p>
<p><em>Estimamos el modelo probit</em>:</p>
<pre class="r"><code>prob_probit &lt;- glm(arr86 ~ pcnv + avgsen + tottime + ptime86 + inc86 + black + hispan + 
    born60, family = binomial(link = &quot;probit&quot;), data = data.grogger)
summary(prob_probit)$coef
##                 Estimate   Std. Error    z value     Pr(&gt;|z|)
## (Intercept) -0.313833303 0.0513645961 -6.1099148 9.968437e-10
## pcnv        -0.552925133 0.0715054868 -7.7326253 1.053511e-14
## avgsen       0.012739470 0.0209105156  0.6092375 5.423670e-01
## tottime     -0.007648510 0.0165677095 -0.4616516 6.443312e-01
## ptime86     -0.081199594 0.0171628579 -4.7311231 2.232811e-06
## inc86       -0.004634612 0.0004852644 -9.5506951 1.288290e-21
## black        0.466607743 0.0718600190  6.4932872 8.398336e-11
## hispan       0.291100547 0.0653906780  4.4517132 8.518788e-06
## born60       0.011206734 0.0556932300  0.2012225 8.405246e-01</code></pre>
<p><em>Para evaluar el cambio en la probabilidad, evaluamos dos distintos valores del índice, uno cuando pcnv es 0.50 y otro cuando es 0.75, mientras que en ambos casos mantenemos el resto de los regresores en los valores especificados. Esto es</em>: <span class="math display">\[P(y=1│X=x,pcnv=0.75)-P(y=1│X=x,pcnv=0.50)\]</span></p>
<pre class="r"><code># Medias de cada variable tottime inc86 ptime86
mean_avgsen = mean(data.grogger$avgsen)
mean_tottime = mean(data.grogger$tottime)
mean_inc86 = mean(data.grogger$inc86)
mean_ptime86 = mean(data.grogger$ptime86)

# Creamos un índice con todas las variables excepto pcnv

index_partial &lt;- summary(prob_probit)$coef[1] + summary(prob_probit)$coef[3] * mean_avgsen + 
    summary(prob_probit)$coef[4] * mean_tottime + summary(prob_probit)$coef[6] * 
    mean_inc86 + summary(prob_probit)$coef[5] * mean_ptime86 + summary(prob_probit)$coef[7] * 
    1 + summary(prob_probit)$coef[8] * 0 + summary(prob_probit)$coef[9] * 1

# Evaluamos la diferencia de probabilidad

pnorm(index_partial + summary(prob_probit)$coef[2] * 0.5) - pnorm(index_partial + 
    summary(prob_probit)$coef[2] * 0.25)
## [1] -0.05222262</code></pre>
<p><em>El efecto es de una disminución de alrededor de 5.22%, menor en magnitud que lo estimado con el modelo lineal.</em></p></li>
</ol>
</div>
<div id="pregunta-8" class="section level2">
<h2>Pregunta 8</h2>
<p>Ahora estimará un modelo multinomial empleando la base <em>motral2012.csv</em>. El propósito será estudiar los factores relevantes para predecir la forma de ahorro que tienen las personas. Considere lo siguiente sobre las opciones de ahorro de los entrevistados, contenida en la variable <strong>p14</strong>:</p>
<ul>
<li><strong>p14</strong> igual a 1 significa cuentas de ahorro bancarias</li>
<li><strong>p14</strong> igual a 2 significa cuenta de inversión bancaria</li>
<li><strong>p14</strong> igual a 3 significa inversiones en bienes raíces</li>
<li><strong>p14</strong> igual a 4 significa caja de ahorro en su trabajo</li>
<li><strong>p14</strong> igual a 5 significa caja de ahorro con sus amigos</li>
<li><strong>p14</strong> igual a 6 significa tandas</li>
<li><strong>p14</strong> igual a 7 significa que ahorra en su casa o alcancías</li>
<li><strong>p14</strong> igual a 8 significa otro lugar</li>
</ul>
<ol style="list-style-type: lower-alpha">
<li><p>[1 punto] Genere una variable categórica llamada <strong>ahorro</strong> que sea igual a 1 cuando <strong>p14</strong> sea igual a 1 o 2, igual a 2 cuando <strong>p14</strong> sea igual a 7, e igual a 3 cuando <strong>p14</strong> sea igual a 3, 4, 5, 6 u 8. Haga que esa variable sea missing cuando <strong>p14</strong> sea missing. Se sugiere que posteriormente etiquete los valores de ahorro de forma que el valor 1 tenga la etiqueta “Banco”, el valor 2 tenga la etiqueta “Casa” y el valor 3 tenga la etiqueta “Otro”.</p>
<pre class="r"><code>data.financiero &lt;- read_csv(&quot;./motral2012.csv&quot;, locale = locale(encoding = &quot;latin1&quot;)) %&gt;% 
    clean_names() %&gt;% mutate(ahorro = NA) %&gt;% mutate(ahorro = ifelse(p14 %in% c(1, 
    2), 1, ahorro)) %&gt;% mutate(ahorro = ifelse(p14 == 7, 2, ahorro)) %&gt;% mutate(ahorro = ifelse(p14 %in% 
    c(3, 4, 5, 6, 8), 3, ahorro)) %&gt;% mutate(ahorro = factor(ahorro, levels = c(1, 
    2, 3), labels = c(&quot;Banco&quot;, &quot;Casa&quot;, &quot;Otro&quot;)))</code></pre></li>
<li><p>[2 puntos] Estime un modelo logit multinomial (regresores invariantes a la alternativa) con la opción de ahorro como variable dependiente. Genere un indicador para las mujeres, <strong>mujer</strong>, a partir de la variable <strong>sex</strong>, que es igual a 1 para los hombres e igual a 2 para las mujeres. Para estimar el modelo use la variable <strong>mujer</strong>, la edad (<strong>eda</strong>) y la educación (<strong>anios_educ</strong>) como variables independientes. ¿Qué puede decir sobre el coeficiente de años de educación en la alternativa “Casa”?</p>
<pre class="r"><code>data.financiero &lt;- data.financiero %&gt;% mutate(mujer = ifelse(sex == 2, 1, 0))

# Usando mlogit
data.subset &lt;- data.financiero %&gt;% select(ahorro, eda, anios_esc, mujer)

data.subset &lt;- dfidx::dfidx(data.subset, shape = &quot;wide&quot;, choice = &quot;ahorro&quot;)

# Noten que aquí 1 significa que no hay variables que varíen entre alternativas,
# luego la barra &#39;|&#39; significa que vienen las variables que varían entre
# alternativas

# Noten también el uso de &#39;::&#39;. Bien podríamos haber cargado al inicio &#39;mlogit&#39;
# con library(mlogit), pero si lo vamos a usar una sola vez, podemos instalarlo y
# solo usar la función que nos interesa.

mmultilogit &lt;- mlogit::mlogit(ahorro ~ 1 | eda + anios_esc + mujer, reflevel = &quot;Banco&quot;, 
    data = data.subset)
summary(mmultilogit)
## 
## Call:
## mlogit::mlogit(formula = ahorro ~ 1 | eda + anios_esc + mujer, 
##     data = data.subset, reflevel = &quot;Banco&quot;, method = &quot;nr&quot;)
## 
## Frequencies of alternatives:choice
##   Banco    Casa    Otro 
## 0.43697 0.30326 0.25977 
## 
## nr method
## 5 iterations, 0h:0m:1s 
## g&#39;(-H)^-1g = 4.05E-06 
## successive function values within tolerance limits 
## 
## Coefficients :
##                    Estimate Std. Error  z-value  Pr(&gt;|z|)    
## (Intercept):Casa  3.0268812  0.2487107  12.1703 &lt; 2.2e-16 ***
## (Intercept):Otro  0.2066997  0.2476498   0.8346 0.4039175    
## eda:Casa         -0.0523103  0.0052074 -10.0453 &lt; 2.2e-16 ***
## eda:Otro         -0.0035014  0.0049641  -0.7053 0.4805997    
## anios_esc:Casa   -0.1482970  0.0135532 -10.9419 &lt; 2.2e-16 ***
## anios_esc:Otro   -0.0462814  0.0128510  -3.6014 0.0003165 ***
## mujer:Casa        0.0926520  0.0995654   0.9306 0.3520793    
## mujer:Otro       -0.0645926  0.0999572  -0.6462 0.5181477    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Log-Likelihood: -2545.7
## McFadden R^2:  0.045172 
## Likelihood ratio test : chisq = 240.87 (p.value = &lt; 2.22e-16)</code></pre>
<p><em>En el modelo multinominal (regresores invariantes) el coeficiente se interpreta con respecto a una categoría base. En este caso, la categoría base es Banco. El modelo implica que la probabilidad de ahorrar en casa disminuye con un año más de educación, en comparación con la probabilidad de ahorrar en el banco. En particular, sabemos que podemos escribir el log del cociente de la probabilidad de las categorías <span class="math inline">\(j\)</span> y <span class="math inline">\(k\)</span> sean escogidas, normalizando <span class="math inline">\(k\)</span> a ser la base, como:</em> <span class="math display">\[\ln\left(\frac{P(y=Casa)}{P(y=Banco)}\right)=x&#39;\beta=\beta_0+\beta_1 edad + \beta_2 educación + \beta_3 mujer \]</span> <em>es decir, un año más de educación se asocia con una reducción en el log de la razón de momios de 0.15.</em></p></li>
<li><p>[2 puntos] Calcule los efectos marginales sobre la probabilidad de ahorrar en el banco. Al considerar el cambio en la probabilidad de para el caso de las mujeres (cuando la variable <strong>mujer</strong> passa de 0 a 1), ¿de qué tamaño es el efecto predicho en la probabilidad de ahorrar en el banco?</p>
<p><em>Esta pregunta era un poco más difícil. Aquí está una propuesta, pero se valorará el trabajo de cada persona.</em></p>
<pre class="r"><code># El efecto marginal individual sobre la probabilidad de elegir cada alternativa
# puede ser calculado como sigue:
stats::effects(mmultilogit, covariate = &quot;anios_esc&quot;, data = data.subset)[1:5, ]
##         Banco        Casa         Otro
## 2  0.01655974 -0.01103283 -0.005526904
## 7  0.02322803 -0.02474450  0.001516472
## 8  0.02169561 -0.03076781  0.009072207
## 9  0.02394915 -0.02780141  0.003852262
## 10 0.01942586 -0.01579358 -0.003632277

# Pero si queremos hacerlo para cada variable y para cada categoría, podemos
# hacer lo siguiente.

# Capturamos los nombres de los coeficientes, que están en las entradas 2, 3 y 4
# que corresponden a las variables que nos interesan
(c.names &lt;- names(mmultilogit$model)[c(2:4)])
## [1] &quot;eda&quot;       &quot;anios_esc&quot; &quot;mujer&quot;

# Programamos una función, que para cada variable calcule el efecto marginal
# individual
efecto_marginal &lt;- sapply(c.names, function(x) stats::effects(mmultilogit, covariate = x, 
    data = data.subset), simplify = FALSE)

# Obtenemos el promedio de los efectos marginales
(promedio_efecto_marginal &lt;- t(sapply(efecto_marginal, colMeans)))
##                  Banco         Casa         Otro
## eda        0.006571596 -0.009824518  0.003252922
## anios_esc  0.022847286 -0.025126560  0.002279274
## mujer     -0.003427594  0.022708463 -0.019280870</code></pre>
<p><em>El efecto de ser mujer es de un incremento de 2.27% en la probabilidad de ahorrar en casa al estimar el promedio de los efectos marginales.</em></p></li>
<li><p>[4 puntos] Calcule los cocientes de riesgo relativo (relative risk ratios, RRR). ¿Qué significa el hecho de que el RRR asociado a ser mujer sea mayor que 1 en la alternativa “Casa”?</p>
<pre class="r"><code>(mmultilogit_rrr = exp(coef(mmultilogit)))
## (Intercept):Casa (Intercept):Otro         eda:Casa         eda:Otro 
##       20.6327835        1.2296133        0.9490344        0.9965047 
##   anios_esc:Casa   anios_esc:Otro       mujer:Casa       mujer:Otro 
##        0.8621750        0.9547732        1.0970799        0.9374493</code></pre>
<p><em>Los coeficientes en forma de RRR tienen la interpretación del cambio en el riesgo relativo que una categoría sea elegida con relación al riesgo de escoger la categoría base. En este caso, el ser mujer está asociado con una probabilidad de ahorrar en “Casa” 1.097 veces mayor de que la de ahorrar en “Banco”.</em></p></li>
<li><p>[1 puntos] Estime nuevamente el modelo, pero ahora, especifique que la alternativa “Casa” sea la alternativa base. ¿Cómo es el RRR de la edad en la alternativa “Banco”? ¿Es esto congruente con lo que obtuvo en la parte d. de este problema?</p>
<pre class="r"><code># Nueva estimación
mmultilogit_casa &lt;- mlogit::mlogit(ahorro ~ 1 | eda + anios_esc + mujer, reflevel = &quot;Casa&quot;, 
    data = data.subset)

(mmultilogit_casa_rrr = exp(coef(mmultilogit_casa)))
## (Intercept):Banco  (Intercept):Otro         eda:Banco          eda:Otro 
##        0.04846656        0.05959512        1.05370263        1.05001966 
##   anios_esc:Banco    anios_esc:Otro       mujer:Banco        mujer:Otro 
##        1.15985732        1.10740073        0.91151067        0.85449501

(mmultilogit_rrr = exp(coef(mmultilogit)))
## (Intercept):Casa (Intercept):Otro         eda:Casa         eda:Otro 
##       20.6327835        1.2296133        0.9490344        0.9965047 
##   anios_esc:Casa   anios_esc:Otro       mujer:Casa       mujer:Otro 
##        0.8621750        0.9547732        1.0970799        0.9374493</code></pre>
<p><em>Al cambiar la categoría base a Casa solo se modifica la interpretación relativa. En la parte d. el RRR de la edad para la opción de Casa era 0.949, es decir, si la edad se incrementa en una unidad, la probabilidad de ahorrar en Casa es 0.949 veces la de ahorrar en Banco. Con la nueva categoría base, el RRR de la edad para ahorrar en Banco es 1.054, es decir, si la edad se incrementa en un año, la probabilidad de ahorrar en Banco es 1.054 veces más probable que la probabilidad de ahorrar en Casa. La parte d. implica que <span class="math inline">\(P(Casa)=0.949(Banco)\)</span>. Mientras que estimando el modelo con la nueva categoría, <span class="math inline">\(P(Banco)=1.054(Casa)\)</span>, o <span class="math inline">\(P(Casa)=1/1.054(Banco)\)</span>. Empleando todos los decimales en R se puede notar que 1/1.054≅0.949 Ambos resultados son consistentes.</em></p></li>
</ol>
</div>
<div id="pregunta-9" class="section level2">
<h2>Pregunta 9</h2>
<p>Use la base de datos <em>phd_articulos.csv</em>, la cual contiene información sobre el número de artículos publicados en los últimos tres años del doctorado para una muestra de entonces estudiantes. Nuestra variable de interés será entonces <strong>art</strong>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>[1 punto] ¿Hay evidencia de sobredispersión en la variable <strong>art</strong>?</p>
<p><em>La media de la variable <strong>art</strong> es 1.69, mientras que la varianza es 3.71. Esto puede ser un indicativo de que un modelo Poisson no es adecuado, pues en una distribución Poisson la media es igual a la varianza. Parce haber evidencia de sobredispersión.</em></p>
<pre class="r"><code>data.phd &lt;- read_csv(&quot;./phd_articulos.csv&quot;, locale = locale(encoding = &quot;latin1&quot;))

# a. Descriptiva
stat.desc(data.phd$art)
##      nbr.val     nbr.null       nbr.na          min          max        range 
## 9.150000e+02 2.750000e+02 0.000000e+00 0.000000e+00 1.900000e+01 1.900000e+01 
##          sum       median         mean      SE.mean CI.mean.0.95          var 
## 1.549000e+03 1.000000e+00 1.692896e+00 6.367388e-02 1.249640e-01 3.709742e+00 
##      std.dev     coef.var 
## 1.926069e+00 1.137736e+00</code></pre></li>
<li><p>[2 puntos] Independientemente de si hay evidencia de sobredispersión o no, estime un modelo Poisson que incluya variables dicotómicas para estudiantes mujeres y para estudiantes casadas o casados, la cantidad de hijos mejores de cinco años, el ranking de prestigio del doctorado (<strong>phd</strong>) y el número de artículos publicados por su mentor. Interprete los coeficientes estimados.</p>
<pre class="r"><code># Hay que asegurarnos que los factores tengan sentido
data.phd &lt;- data.phd %&gt;% mutate(female = factor(female, levels = c(&quot;Male&quot;, &quot;Female&quot;)))

mpoisson &lt;- glm(art ~ factor(female) + factor(married) + kid5 + phd + mentor, family = &quot;poisson&quot;, 
    data = data.phd)

summary(mpoisson)
## 
## Call:
## glm(formula = art ~ factor(female) + factor(married) + kid5 + 
##     phd + mentor, family = &quot;poisson&quot;, data = data.phd)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.5672  -1.5398  -0.3660   0.5722   5.4467  
## 
## Coefficients:
##                        Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)            0.459860   0.093335   4.927 8.35e-07 ***
## factor(female)Female  -0.224594   0.054613  -4.112 3.92e-05 ***
## factor(married)Single -0.155243   0.061374  -2.529   0.0114 *  
## kid5                  -0.184883   0.040127  -4.607 4.08e-06 ***
## phd                    0.012823   0.026397   0.486   0.6271    
## mentor                 0.025543   0.002006  12.733  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for poisson family taken to be 1)
## 
##     Null deviance: 1817.4  on 914  degrees of freedom
## Residual deviance: 1634.4  on 909  degrees of freedom
## AIC: 3314.1
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p><em>Para las variables continuas, como el número de artículos publicados por el mentor, la interpretación es el cambio en el log conteo esperado. En este caso, un artículo más publicado por el mentor incrementa el log conteo esperado en 0.026. O, siguiendo el razonamiento de la parte b. de la pregunta 9, la semielasticidad del conteo con respecto al número de artículos publicados es 0.026. Para las variables dicotómicas, por ejemplo female, la interpretación es la diferencia entre el log conteo esperado entre mujeres y la categoría base (hombres).</em></p></li>
<li><p>[2 puntos] Obtenga la razón de tasas de incidencia (IRR) para los coeficientes e interprete los resultados.</p>
<pre class="r"><code>exp(summary(mpoisson)$coef)
##                        Estimate Std. Error      z value Pr(&gt;|z|)
## (Intercept)           1.5838526   1.097829 1.379638e+02 1.000001
## factor(female)Female  0.7988403   1.056132 1.636793e-02 1.000039
## factor(married)Single 0.8562068   1.063297 7.970295e-02 1.011490
## kid5                  0.8312018   1.040943 9.977222e-03 1.000004
## phd                   1.0129051   1.026749 1.625407e+00 1.872246
## mentor                1.0258718   1.002008 3.386456e+05 1.000000</code></pre>
<p><em>La interpretación de los coeficientes se vuelve más sencilla usando irr. Para la variable continua mentor, un artículo más publicado por el mentor está asociado con 1.026 veces más artículos publicados por el estudiante, es decir, un 2.6% más artículos. En cambio, la variable dicotómica para mujeres indica que las mujeres publican 0.8 veces el número de artículos que los hombres.</em></p></li>
<li><p>[1 punto] Considere ahora que las mujeres han tenido carreras profesionales más cortas que los hombres, es decir, han estado menos expuestas a la ocurrencia de los eventos “publicar”. Incorpore esto al análisis y reinterprete los resultados. Pista: explore la opción <em>offeset</em> en R. Note que la variable <strong>profage</strong> mide la duración efectiva de las carreras profesionales de cada individuo.</p>
<p><em>El razonamiento es que ahora queremos conocer cuál es la tasa de publicación, es decir, <span class="math inline">\(art/profage\)</span>. Pero como nuestro podemos Poisson solo puede manejar conteos, podemos modificar el modelo para pasar la edad de la carrera del lado derecho:</em> <span class="math display">\[\begin{aligned} ln(art/profage)&amp;=x&#39;\beta \\ ln(art)&amp;=x&#39;\beta+\ln(profage) \end{aligned}\]</span></p>
<pre class="r"><code>mpoisson_duracion &lt;- glm(art ~ factor(female) + factor(married) + kid5 + phd + mentor, 
    offset = log(profage), family = &quot;poisson&quot;, data = data.phd)

summary(mpoisson_duracion)$coef
##                          Estimate  Std. Error     z value      Pr(&gt;|z|)
## (Intercept)           -2.95404558 0.093812104 -31.4889600 1.230266e-217
## factor(female)Female   0.45874678 0.054721432   8.3833109  5.145931e-17
## factor(married)Single -0.15598278 0.061347334  -2.5426171  1.100257e-02
## kid5                  -0.18643454 0.040135522  -4.6451256  3.398696e-06
## phd                    0.01801602 0.026428953   0.6816773  4.954430e-01
## mentor                 0.02573493 0.002001731  12.8563329  7.924799e-38</code></pre>
<p><em>Hasta ahora hemos asumido que cada individuo ha estado “en riesgo” de publicar por el mismo periodo de tiempo, lo cual puede ser no cierto si, por ejemplo, algunos estudiantes se graduaron antes, o si otros han tenido pausas en sus carreras. Al controlar por el hecho de que las mujeres han tenido carreras más cortas, la variable female deja de ser negativa y se convierte en positiva. Las mujeres publican más que los hombres al tomar en cuenta la duración de las carreras.</em></p></li>
<li><p>[2 puntos] Emplee ahora un modelo negativo binomial con sobredispersión constante para estimar la relación entre el número de artículos publicados y las variables explicativas antes enumeradas. Interprete el coeficiente asociado al número de hijos y a la variable dicotómica para estudiantes mujeres.</p>
<p><em>Este es el modelo NB1 visto en clase y el menos usado de las dos posibles especificaciones del modelo negativo binomial. Se asume que la sobredispersión es un factor constante de la media. Los coeficientes tienen exactamente la misma interpretación que en el modelo Poisson pues en ambos casos la media está parametrizada de la misma manera. Más aún, los coeficientes estimados apenas difieren de la versión Poisson. Para estimar este modelo usé ml.nb1 del paquete COUNT.</em></p>
<pre class="r"><code>mnb1 &lt;- COUNT::ml.nb1(art ~ factor(female) + factor(married) + kid5 + phd + mentor, 
    data = data.phd)

# Aquí \alpha es el parámetro \gamma descrito en el quinto párrafo de la página
# 676 en CT
mnb1
##                          Estimate          SE          Z         LCL
## (Intercept)            0.39932986 0.120678876  3.3090287  0.16279926
## factor(female)Female  -0.18336608 0.069842879 -2.6254084 -0.32025813
## factor(married)Single -0.15473849 0.078712292 -1.9658746 -0.30901459
## kid5                  -0.17284325 0.051082365 -3.3836187 -0.27296468
## phd                    0.03032082 0.033987903  0.8921061 -0.03629547
## mentor                 0.02412048 0.002599684  9.2782354  0.01902510
## alpha                  0.79174542 0.097242882  8.1419370  0.60114937
##                                 UCL
## (Intercept)            0.6358604598
## factor(female)Female  -0.0464740398
## factor(married)Single -0.0004624015
## kid5                  -0.0727218098
## phd                    0.0969371064
## mentor                 0.0292158556
## alpha                  0.9823414685</code></pre></li>
<li><p>[2 puntos] Emplee ahora un modelo negativo binomial con sobredispersión cuadrática en la media para estimar la relación entre el número de artículos publicados y las variables explicativas antes enumeradas. Interprete el coeficiente asociado al número de hijos y a la variable dicotómica para estudiantes mujeres. ¿Qué puede decir sobre la significancia del <span class="math inline">\(\alpha\)</span> estimado?</p>
<pre class="r"><code>mnb2 &lt;- MASS::glm.nb(art ~ factor(female) + factor(married) + kid5 + phd + mentor, 
    data = data.phd)
summary(mnb2)
## 
## Call:
## MASS::glm.nb(formula = art ~ factor(female) + factor(married) + 
##     kid5 + phd + mentor, data = data.phd, init.theta = 2.264387695, 
##     link = log)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -2.1678  -1.3617  -0.2806   0.4476   3.4524  
## 
## Coefficients:
##                        Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)            0.406633   0.125778   3.233 0.001225 ** 
## factor(female)Female  -0.216418   0.072636  -2.979 0.002887 ** 
## factor(married)Single -0.150489   0.082097  -1.833 0.066791 .  
## kid5                  -0.176415   0.052813  -3.340 0.000837 ***
## phd                    0.015271   0.035873   0.426 0.670326    
## mentor                 0.029082   0.003214   9.048  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for Negative Binomial(2.2644) family taken to be 1)
## 
##     Null deviance: 1109.0  on 914  degrees of freedom
## Residual deviance: 1004.3  on 909  degrees of freedom
## AIC: 3135.9
## 
## Number of Fisher Scoring iterations: 1
## 
## 
##               Theta:  2.264 
##           Std. Err.:  0.271 
## 
##  2 x log-likelihood:  -3121.917

# A diferencia de otros paquetes, R reporta \theta=1/\alpha
(alpha &lt;- 1/summary(mnb2)$theta)
## [1] 0.4416205</code></pre>
<p><em>Este es el modelo NB2 visto en clase y la forma más usada para implementar un modelo negativo binomial. Se asume una sobredispersión cuadrática en la media, con la varianza parametrizada usando <span class="math inline">\(\alpha\)</span>. En este caso, <span class="math inline">\(\hat{\alpha}=0.44\)</span> y es estadísticamente significativo al 10%. De nuevo, la interpretación se mantiene con respecto a NB1 y al modelo Poisson. Los coeficientes tienen magnitudes similares, pero se prefiere el modelo NB2 pues toma en cuenta la sobredispersión y le da suficiente flexibilidad a la varianza para depender de manera cuadrática de la media.</em></p></li>
</ol>
</div>
