---
title: "Respuestas a la tarea 3"
summary: " "
weight: 2
type: book
toc: false
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="instrucciones" class="section level2">
<h2>Instrucciones</h2>
</div>
<div id="respuestas" class="section level2">
<h2>Respuestas</h2>
</div>
<div id="pregunta-1" class="section level2">
<h2>Pregunta 1</h2>
<p>Considere la base de datos <em>comportamiento_wide.csv</em>. Esta base contiene información individual de niñas y niños, incluyendo su género, edad, raza e información de sus madres. Además, se incluye una medida auto reportada de autoestima (<strong>self</strong>) y una evaluación de comportamiento antisocial (<strong>anti</strong>). Se quiere conocer cómo influye la autoestima en el comportamiento antisocial. Para cada niño o niña hay tres observaciones en el tiempo. Se busca explicar el comportamiento antisocial en función de la autoestima y la condición de pobreza (<strong>pov</strong>):</p>
<p><span class="math display">\[anti_{it}=\alpha_i+\beta_1 self_{it}+\beta_2 pov_{it}+\varepsilon_{it}\]</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>[3 puntos] La base se encuentra en formato <em>wide</em>. Ponga la base en formato <em>long</em>, donde haya una columna para cada variable y donde las filas representen a un individuo en un periodo.</p>
<p><em>Hay muchas formas de hacer esto. Podemos usar las funciones pivot_longer y pivot_wider, por ejemplo.</em></p>
<pre class="r"><code>data.comp &lt;- read_csv(&quot;./comportamiento_wide.csv&quot;, locale = locale(encoding = &quot;latin1&quot;)) %&gt;%
    pivot_longer(c(anti90:anti94, self90:self94, pov90:pov94), names_to = c(&quot;measure&quot;,
        &quot;year&quot;), names_pattern = &quot;(.*)(..)&quot;) %&gt;%
    pivot_wider(names_from = measure, values_from = value)

colnames(data.comp)
##  [1] &quot;id&quot;       &quot;momage&quot;   &quot;gender&quot;   &quot;childage&quot; &quot;hispanic&quot; &quot;black&quot;   
##  [7] &quot;momwork&quot;  &quot;married&quot;  &quot;year&quot;     &quot;anti&quot;     &quot;self&quot;     &quot;pov&quot;</code></pre></li>
<li><p>[2 puntos] Estime la ecuación de comportamiento antisocial empleando MCO <em>pooled</em>. ¿Cuáles son los supuestos que se deben cumplir para que <span class="math inline">\(\hat{\beta}_1^{MCO}\)</span> sea consistente?</p>
<pre class="r"><code>summary(m.mco &lt;- plm(anti ~ self + pov, data = data.comp, model = &quot;pooling&quot;, index = c(&quot;id&quot;,
    &quot;year&quot;)))
## Pooling Model
## 
## Call:
## plm(formula = anti ~ self + pov, data = data.comp, model = &quot;pooling&quot;, 
##     index = c(&quot;id&quot;, &quot;year&quot;))
## 
## Balanced Panel: n = 581, T = 3, N = 1743
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -2.65689 -1.29476 -0.33138  0.98912  4.77034 
## 
## Coefficients:
##              Estimate Std. Error t-value  Pr(&gt;|t|)    
## (Intercept)  2.792098   0.231110 12.0812 &lt; 2.2e-16 ***
## self        -0.065102   0.011083 -5.8739 5.089e-09 ***
## pov          0.515809   0.078730  6.5516 7.476e-11 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    4333.1
## Residual Sum of Squares: 4140.6
## R-Squared:      0.044433
## Adj. R-Squared: 0.043335
## F-statistic: 40.4544 on 2 and 1740 DF, p-value: &lt; 2.22e-16</code></pre>
<p><em>La variable self tiene un efecto negativo y estadísticamente significativo sobre anti. La variable pov tiene un efecto positivo y estadísticamente significativo. El estimador de MCO será consistente solo si las variables self y pov no están correlacionadas con el error. Además, para estimar este modelo, asumimos que la heterogeneidad no observada <span class="math inline">\(\alpha_i\)</span> puede escribirse simplemente como <span class="math inline">\(\alpha\)</span>. Otra forma de pensar sobre este modelo es si el mismo modelo es válido para todos los periodos como para asumir una ordenada al origen y una pendiente común. El modelo pooled ignora la naturaleza en panel de los datos. Sin embargo, como tenemos a los mismos individuos en varios puntos del tiempo, los errores están agrupados, así que se deben de estimar errores con esta estructura. En este caso, al tomar en cuenta esta correlación entre grupos, los errores estándar son más grandes, pero los resultados siguen siendo significativos. En muchos casos, no tomar en cuenta la estructura agrupada de los errores puede llevar a rechazar hipótesis nulas que son ciertas.</em></p>
<pre class="r"><code>coeftest(m.mco, vcov = vcovHC(m.mco, type = &quot;HC1&quot;, cluster = &quot;group&quot;))
## 
## t test of coefficients:
## 
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  2.792098   0.293380  9.5170 &lt; 2.2e-16 ***
## self        -0.065102   0.013687 -4.7565 2.132e-06 ***
## pov          0.515809   0.104963  4.9142 9.753e-07 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre></li>
<li><p>[5 puntos] Estime la ecuación de comportamiento antisocial empleando efectos fijos. ¿Cuáles son los supuestos que se deben cumplir para que <span class="math inline">\(\hat{\beta}_1^{FE}\)</span> sea consistente?</p>
<p><em>Si asumimos que la heterogeneidad no observada y el error están potencialmente correlacionados, entonces podemos usar un estimador de efectos fijos para deshacernos de la heterogeneidad no observada y estimar consistentemente los parámetros sobre self y pov.</em></p>
<pre class="r"><code>m.fe &lt;- plm(anti ~ self + pov, data = data.comp, model = &quot;within&quot;, index = c(&quot;id&quot;,
    &quot;year&quot;))

coeftest(m.fe, vcov = vcovHC(m.fe, type = &quot;HC1&quot;, cluster = &quot;group&quot;))
## 
## t test of coefficients:
## 
##       Estimate Std. Error t value  Pr(&gt;|t|)    
## self -0.051495   0.011308 -4.5540 5.818e-06 ***
## pov   0.104899   0.099188  1.0576    0.2905    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre></li>
<li><p>[5 puntos] Estime la ecuación de comportamiento antisocial empleando efectos aleatorios. ¿Cuáles son los supuestos que se deben cumplir para que <span class="math inline">\(\hat{\beta}_1^{RE}\)</span> sea consistente?</p>
<p><em>Si estamos dispuestos a asumir que la heterogeneidad no observada y el error son independientes, podemos emplear el estimador de efectos aleatorios. MCO pooled también es consistente pero no es eficiente.</em></p>
<pre class="r"><code>m.re &lt;- plm(anti ~ self + pov, data = data.comp, model = &quot;random&quot;, index = c(&quot;id&quot;,
    &quot;year&quot;))

coeftest(m.re, vcov = vcovHC(m.re, type = &quot;HC1&quot;, cluster = &quot;group&quot;))
## 
## t test of coefficients:
## 
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  2.695210   0.222607 12.1075 &lt; 2.2e-16 ***
## self        -0.056732   0.010216 -5.5534 3.234e-08 ***
## pov          0.292407   0.081956  3.5679 0.0003696 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre></li>
<li><p>[5 puntos] Se desea incorporar en el análisis el género (<strong>gender</strong>) y una variable dicotómica para los hispanos (<strong>hispanic</strong>). Indique qué modelo usaría y estime dicho modelo.</p>
<p><em>No es posible estimar los coeficientes sobre variables que no varían en el tiempo usando efectos fijos, por lo que este modelo queda descartado. Podríamos usar MCO pooled, que impone supuestos muy fuertes. La otra alternativa es un modelo de efectos aleatorios, que asume que la heterogeneidad no observada y el error no están correlacionados.</em></p>
<pre class="r"><code>m.sex &lt;- plm(anti ~ self + pov + gender, data = data.comp, model = &quot;random&quot;, index = c(&quot;id&quot;,
    &quot;year&quot;))

coeftest(m.sex, vcov = vcovHC(m.sex, type = &quot;HC1&quot;, cluster = &quot;group&quot;))
## 
## t test of coefficients:
## 
##              Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)  2.970534   0.231591 12.8267 &lt; 2.2e-16 ***
## self        -0.058558   0.010223 -5.7278 1.197e-08 ***
## pov          0.304997   0.081486  3.7429 0.0001878 ***
## gender      -0.480468   0.107126 -4.4851 7.766e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre></li>
<li><p>[5 puntos] Regrese al modelo que incluye solo la autoestima y el estado de pobreza como covariables. Realice una prueba de Hausman para determinar si se prefiere un modelo de efectos fijos o uno de efectos aleatorios.</p>
<p><em>La implementación de la prueba de Hausman indica que se rechaza la H0 de que los coeficientes estimados son iguales (y que el modelo de efectos aleatorios es el adecuado). Hay evidencia de que se prefiere un modelo de efectos fijos, aunque tendremos que vivir con el hecho de no poder estimar el coeficiente asociado a las variables que no varían en el tiempo en este caso.</em></p>
<pre class="r"><code>phtest(m.fe, m.re)
## 
##  Hausman Test
## 
## data:  anti ~ self + pov
## chisq = 13.578, df = 2, p-value = 0.001126
## alternative hypothesis: one model is inconsistent</code></pre></li>
</ol>
</div>
<div id="pregunta-2" class="section level1">
<h1>Pregunta 2</h1>
<p>Cuando trabajamos con datos en panel tenemos dos fuentes de variación. Como los individuos difieren entre sí, por ejemplo, algunos tienen mayor habilidad que otros o algunos tienen mayor salario que otros, la primer fuente de variación es la que proviene de comparar entre unidades. Esta primer fuente de variación es la <strong>variación between</strong>. La variación between se define como:</p>
<p><span class="math display">\[s^2_B=\frac{1}{N-1}\sum_i(\bar{x}_i-\bar{x})^2\]</span></p>
<p>En la expresión anterior <span class="math inline">\(\bar{x}_i=\frac{1}{T}\sum_t x_{it}\)</span> es el promedio de la característica <span class="math inline">\(x\)</span> para un individuo a lo largo del tiempo. Por tanto, <span class="math inline">\((\bar{x}_i-\bar{x})\)</span> compara esta característica promedio con el promedio de todos los individuos <span class="math inline">\(\bar{x}=\frac{1}{NT}\sum_i\sum_t x_{it}\)</span>.</p>
<p>La segunda fuente de variación surge porque las características de los individuos varían a lo largo del tiempo. A esta variación se le llama <strong>variación within</strong>. La variación within se define como:</p>
<p><span class="math display">\[s_W^2=\frac{1}{NT-1}\sum_i\sum_t(x_{it}-\bar{x}_i)^2\]</span>
Así, la varianza total se define como:</p>
<p><span class="math display">\[s_O^2=\frac{1}{NT-1}\sum_i\sum_t(x_{it}-\bar{x})\approx s^2_B+s^2_W\]</span>
Considere la base de datos <em>individuos_empleo_wide.csv</em>. Esta base de datos contiene información de trabajadores relativa a su salario, su educación y experiencia. En este ejercicio comprobará los resultados vistos en clase respecto al modelo de efectos fijos.</p>
<ol style="list-style-type: lower-alpha">
<li><p>[1 puntos] La base de datos está en formato <em>wide</em>. Coloque sus datos en formato <em>long</em>.</p>
<p><em>De forma análoga a como hicimos en la pregunta 1:</em></p>
<pre class="r"><code>data.empleo &lt;- read_csv(&quot;./individuos_empleo_wide.csv&quot;, locale = locale(encoding = &quot;latin1&quot;)) %&gt;%
    pivot_longer(choice2011:status2017, names_to = c(&quot;measure&quot;, &quot;year&quot;), names_pattern = &quot;(.*)(....)&quot;) %&gt;%
    pivot_wider(names_from = measure, values_from = value)</code></pre></li>
<li><p>[2 puntos] ¿Cómo es la variación <em>within</em> y <em>between</em> de la variable <strong>wage</strong>? Cuando trabajaba en Stata, esto era muy fácil de hacer con el comando <em>xtsum</em>. Pero no he encontrado una función que haga lo mismo e R. Para calcular entonces las varianzas, use la siguiente función<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a>:</p>
<pre class="r"><code>XTSUM &lt;- function(data, varname, unit) {
  varname &lt;- enquo(varname)
  loc.unit &lt;- enquo(unit)
  ores &lt;- data %&gt;% summarise(ovr.mean=mean(!! varname, na.rm=TRUE), ovr.sd=sd(!! varname, na.rm=TRUE), ovr.min = min(!! varname, na.rm=TRUE), ovr.max=max(!! varname, na.rm=TRUE), ovr.N=sum(as.numeric((!is.na(!! varname)))))
  bmeans &lt;- data %&gt;% group_by(!! loc.unit) %&gt;% summarise(meanx=mean(!! varname, na.rm=T), t.count=sum(as.numeric(!is.na(!! varname))))
  bres &lt;- bmeans %&gt;% ungroup() %&gt;% summarise(between.sd = sd(meanx, na.rm=TRUE), between.min = min(meanx, na.rm=TRUE), between.max=max(meanx, na.rm=TRUE), Units=sum(as.numeric(!is.na(t.count))), t.bar=mean(t.count, na.rm=TRUE))
  wdat &lt;- data %&gt;% group_by(!! loc.unit) %&gt;% mutate(W.x = scale(!! varname, scale=FALSE))
  wres &lt;- wdat %&gt;% ungroup() %&gt;% summarise(within.sd=sd(W.x, na.rm=TRUE), within.min=min(W.x, na.rm=TRUE), within.max=max(W.x, na.rm=TRUE))
  return(list(ores=ores,bres=bres,wres=wres))
}</code></pre>
<p>Posteriormente, estime la varianza within, between y total como sigue:</p>
<pre class="r"><code>XTSUM(data=DATA, varname=x, unit=id)</code></pre>
<p>¿Cuál es mayor y por qué? Puede auxiliarse de <a href="http://stephenporter.org/files/xtsum_handout.pdf">este documento</a> para la interpretación.</p>
<p><em>Siguiendo el procedimiento recomendado obtenemos:</em></p>
<pre class="r"><code>XTSUM(data.empleo, varname=wage, unit=id)</code></pre>
<pre><code>## $ores
## # A tibble: 1 x 5
##   ovr.mean ovr.sd ovr.min ovr.max ovr.N
##      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
## 1   17311. 13725.    827.  341200  2388
## 
## $bres
## # A tibble: 1 x 5
##   between.sd between.min between.max Units t.bar
##        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     14480.       1263.      302400   769  3.11
## 
## $wres
## # A tibble: 1 x 3
##   within.sd within.min within.max
##       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
## 1     8786.    -89188.    254817.</code></pre>
<p><em>La variable wage presenta una varianza grande. Sin embargo, esta proviene sobre todo de la variación between, es decir, de la variación entre individuos. La variación within es mucho más pequeña, pues esta es la variación de los individuos en el tiempo. Esto era de esperarse pues los salarios tienen alta correlación serial.</em></p></li>
<li><p>[2 puntos] Repita el procedimiento anterior para la variable <strong>black</strong>. ¿Qué sucede en este caso?</p>
<pre class="r"><code>XTSUM(data.empleo, varname=black, unit=id)</code></pre>
<pre><code>## $ores
## # A tibble: 1 x 5
##   ovr.mean ovr.sd ovr.min ovr.max ovr.N
##      &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;
## 1    0.348  0.476       0       1  5206
## 
## $bres
## # A tibble: 1 x 5
##   between.sd between.min between.max Units t.bar
##        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1      0.475           0           1   769  6.77
## 
## $wres
## # A tibble: 1 x 3
##   within.sd within.min within.max
##       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;
## 1         0          0          0</code></pre>
<p><em>La variable black identifica a los individuos de raza negra, por lo que no varía en el tiempo. Por tanto, la variación within es cero. La variación total proviene solo de la variación between, es decir, entre individuos.</em></p></li>
<li><p>[5 puntos] Para estudiar la regresión entre salario y experiencia se propone estudiar el siguiente modelo: <span class="math display">\[wage_{it}=\alpha_i+\beta exper_{it}+\varepsilon_{it}\]</span> Compruebe que el estimador de efectos fijos es equivalente a MCO con dummies de individuos.</p>
<p><em>Comprobamos:</em></p>
<pre class="r"><code>m.within &lt;- plm( wage ~ exper, data=data.empleo, model=&quot;within&quot;, index = c(&quot;id&quot;, &quot;year&quot;))
m.dummy &lt;- lm(wage ~ exper+factor(id), data=data.empleo)

stargazer(m.within, m.dummy, keep=&quot;exper&quot;, type=&quot;text&quot;)</code></pre>
<pre><code>## 
## =======================================================================
##                                     Dependent variable:                
##                     ---------------------------------------------------
##                                            wage                        
##                               panel                      OLS           
##                              linear                                    
##                                (1)                       (2)           
## -----------------------------------------------------------------------
## exper                     1,873.010***              1,873.010***       
##                             (137.722)                 (137.722)        
##                                                                        
## -----------------------------------------------------------------------
## Observations                  2,388                     2,388          
## R2                            0.097                     0.630          
## Adjusted R2                  -0.253                     0.487          
## Residual Std. Error                             9,834.575 (df = 1720)  
## F Statistic         184.959*** (df = 1; 1720) 4.392*** (df = 667; 1720)
## =======================================================================
## Note:                                       *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre></li>
<li><p>[5 puntos] Compruebe que en un modelo de efectos fijos las características que no varían en el tiempo no pueden ser identificadas. Use la variable <strong>black</strong> para comprobarlo.</p>
<p><em>Comprobamos que la variable simplemente es omitida del análisis:</em></p>
<pre class="r"><code>summary(plm( wage ~ exper+black, data=data.empleo, model=&quot;within&quot;, index = c(&quot;id&quot;, &quot;year&quot;)))</code></pre>
<pre><code>## Oneway (individual) effect Within Model
## 
## Call:
## plm(formula = wage ~ exper + black, data = data.empleo, model = &quot;within&quot;, 
##     index = c(&quot;id&quot;, &quot;year&quot;))
## 
## Unbalanced Panel: n = 667, T = 1-7, N = 2388
## 
## Residuals:
##     Min.  1st Qu.   Median  3rd Qu.     Max. 
## -90124.4  -2058.2      0.0   1951.9 251070.5 
## 
## Coefficients:
##       Estimate Std. Error t-value  Pr(&gt;|t|)    
## exper  1873.01     137.72    13.6 &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Total Sum of Squares:    1.8425e+11
## Residual Sum of Squares: 1.6636e+11
## R-Squared:      0.097093
## Adj. R-Squared: -0.25305
## F-statistic: 184.959 on 1 and 1720 DF, p-value: &lt; 2.22e-16</code></pre></li>
<li><p>[5 puntos] Compruebe que el estimador de efectos fijos es equivalente a MCO sobre el modelo en diferencias con respecto a la media. Para esto, conserve dos años consecutivos de datos y solo observaciones que tengan datos para salarios y experiencia en los dos años que elija. Luego estime por MCO el modelo con variables transformadas.</p>
<p><em>Nos quedamos con un subconjunto de datos:</em></p>
<pre class="r"><code>data.empleo.sub &lt;- data.empleo %&gt;% 
  dplyr::select(id,year,wage,exper) %&gt;% 
  filter(year==2015 | year==2016)

#Nos quedamos con los que no son NA
data.empleo.sub &lt;- data.empleo.sub[complete.cases(data.empleo.sub), ]</code></pre>
<p><em>Creamos las variables como diferencias respecto a la media y estimamos el modelo within y el modelo de MCO en las variables transformadas:</em></p>
<pre class="r"><code>data.empleo.sub &lt;- data.empleo.sub %&gt;%
  group_by(id) %&gt;% 
  mutate(m.wage=mean(wage), m.exper=mean(exper)) %&gt;% 
  mutate(dm.wage=wage-m.wage, dm.exper=exper-m.exper)

m.demean &lt;- lm(dm.wage ~ dm.exper, data.empleo.sub)
m.within &lt;- plm( wage ~ exper, data=data.empleo.sub, model=&quot;within&quot;, index = c(&quot;id&quot;, &quot;year&quot;))

stargazer(m.within, m.demean, keep=c(&quot;exper&quot;,&quot;dm.exper&quot;), type=&quot;text&quot;)</code></pre>
<pre><code>## 
## ====================================================================
##                                   Dependent variable:               
##                     ------------------------------------------------
##                              wage                   dm.wage         
##                              panel                    OLS           
##                             linear                                  
##                               (1)                     (2)           
## --------------------------------------------------------------------
## exper                    2,446.339***                               
##                            (342.344)                                
##                                                                     
## dm.exper                                          2,446.339***      
##                                                    (211.221)        
##                                                                     
## --------------------------------------------------------------------
## Observations                  840                     840           
## R2                           0.138                   0.138          
## Adjusted R2                 -1.267                   0.137          
## Residual Std. Error                           2,671.753 (df = 838)  
## F Statistic         51.063*** (df = 1; 319) 134.141*** (df = 1; 838)
## ====================================================================
## Note:                                    *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre></li>
<li><p>[5 puntos] Compruebe que el estimador de efectos fijos es equivalente a MCO sobre el modelo en primeras diferencias. Parta de la muestra con dos años de la parte d. para estimar por MCO el modelo con variables transformadas.</p>
<p><em>Usando el mismo subconjunto, calculamos ahora las primeras diferencias y estimamos:</em></p>
<pre class="r"><code>data.empleo.sub &lt;- data.empleo.sub %&gt;%
  group_by(id) %&gt;% 
  mutate(d.wage=wage-dplyr::lag(wage, order_by = year),
     d.exper=exper-dplyr::lag(exper, order_by = year)) %&gt;% 
  ungroup()


m.difs &lt;- lm(d.wage ~ d.exper-1, data=data.empleo.sub)

stargazer(m.within, m.difs, keep=c(&quot;exper&quot;,&quot;d.expr&quot;), type=&quot;text&quot;)</code></pre>
<pre><code>## 
## ===========================================================
##                                  Dependent variable:       
##                           ---------------------------------
##                               wage            d.wage       
##                              panel             OLS         
##                              linear                        
##                               (1)              (2)         
## -----------------------------------------------------------
## exper                     2,446.339***                     
##                            (342.344)                       
##                                                            
## d.exper                                    2,446.339***    
##                                             (342.344)      
##                                                            
## -----------------------------------------------------------
## Observations                  840              320         
## R2                           0.138            0.138        
## Adjusted R2                  -1.267           0.135        
## Residual Std. Error                    6,124.040 (df = 319)
## F Statistic (df = 1; 319)  51.063***        51.063***      
## ===========================================================
## Note:                           *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01</code></pre></li>
</ol>
</div>
<div id="pregunta-3" class="section level1">
<h1>Pregunta 3</h1>
<p>La librería <em>ExPanDaR</em> es muy úti para visualizar datos en formato de panel. Use la base en formato <em>long</em> que construyó para la pregunta 2.</p>
<ol style="list-style-type: lower-alpha">
<li><p>[5 puntos] Use la función <em>ExPanD</em> para crear una aplicación interactiva que le permita explorar sus datos. Un aspecto que puede apreciar es el porcentaje de datos faltantes. ¿Qué variable tiene el mayor porcentaje de <em>NA</em>?</p>
<p><em>Generamos la aplicación. Pueden navegar en y jugar con ella.</em></p>
<pre class="r"><code>ExPanD(df = data.empleo, ts_id=&quot;year&quot;, cs_id=&quot;id&quot;,
   title = &quot;Wow, mis datos&quot;,
   abstract = &quot;Datos tomados de algún lado.&quot;)</code></pre>
<p><em>Claramente, es la variable wage la que tiene mayor cantidad de NAs, sobre todo, en los primeros años del panel.</em></p></li>
<li><p>[5 puntos] No siempre es útil crear una aplicación interactiva. Usando funciones, puede crear aspectos específicos objetos en la aplicación interactiva y trabajar con ellos de acuerdo a sus necesidades. Por ejemplo, use la función <em>prepare_missing_values_graph</em> de este paquete para visualizar el porcentaje de datos faltantes.</p>
<p><em>Si solo nos importan ciertas partes del análisis, podemos obtenerlas por separado. Por ejemplo:</em></p>
<pre class="r"><code>prepare_missing_values_graph(data.empleo,
  ts_id = &quot;year&quot;)</code></pre>
<p><img src="/tareas/tarea_3/tarea_3_respuestas_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p></li>
</ol>
</div>
<div id="pregunta-4" class="section level1">
<h1>Pregunta 4</h1>
<p>Considere la base de datos <em>mlbook1.csv</em>. Esta base contiene información sobre 2287 estudiantes en 131 escuelas. Nos interesa la relación entre una medida de aptitud verbal, (<strong>iq_vert</strong>) y el resultado de un examen de inglés (<strong>langpost</strong>). Las variables <strong>schoolnr</strong> y <strong>pupilnr</strong> identifican a las escuelas y los estudiantes, respectivamente. El modelo a estimar es el siguiente:</p>
<p><span class="math display">\[langpost_{i}=\alpha+\beta iqvert_{i}+BX_{i}+\varepsilon_{i}\]</span>
donde <span class="math inline">\(i\)</span> indexa y <span class="math inline">\(X_i\)</span> son tres características usadas como control: el sexo, <strong>sex</strong>, si el estudiante es de una población minoritaria, <strong>minority</strong> y el número de años repetidos, <strong>repeatgr</strong>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>[3 puntos] ¿Por qué es posible que estemos frente a una situación de errores agrupados?</p>
<p><em>Los datos están agrupados a nivel escuela. Los estudiantes en una misma escuela comparten características observadas y no observadas que hacen que cada estudiante adicional en la muestra provea menos información que la que proporcionaría un estudiante independiente tomado al azar.</em></p></li>
<li><p>[2 puntos] Estime la ecuación de calificación usando MCO ignorando la agrupación de datos. ¿Qué concluye respecto a la relación entre la aptitud verbal y la prueba de inglés?</p>
<p><em>Se concluye que una hora más en la prueba de aptitud incrementa en 2.49 puntos la calificación del examen. El error estándar es 0.072.</em></p>
<pre class="r"><code>data.examen&lt;-read_csv(&quot;./mlbook1.csv&quot;,
                  locale = locale(encoding = &quot;latin1&quot;)) </code></pre>
<pre><code>## Rows: 2287 Columns: 25</code></pre>
<pre><code>## -- Column specification --------------------------------------------------------
## Delimiter: &quot;,&quot;
## dbl (25): schoolnr, pupilnr, iq_verb, iq_perf, sex, minority, repeatgr, arit...</code></pre>
<pre><code>## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<pre class="r"><code>summary(m.mco &lt;- lm(langpost ~ iq_verb + sex + minority + repeatgr, data=data.examen))</code></pre>
<pre><code>## 
## Call:
## lm(formula = langpost ~ iq_verb + sex + minority + repeatgr, 
##     data = data.examen)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -28.0192  -4.2255   0.5218   4.8017  24.1421 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 10.93980    0.90504  12.088   &lt;2e-16 ***
## iq_verb      2.48635    0.07233  34.374   &lt;2e-16 ***
## sex          2.42228    0.28871   8.390   &lt;2e-16 ***
## minority    -0.03701    0.62762  -0.059    0.953    
## repeatgr    -4.40860    0.43222 -10.200   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.853 on 2282 degrees of freedom
## Multiple R-squared:  0.4217, Adjusted R-squared:  0.4207 
## F-statistic: 416.1 on 4 and 2282 DF,  p-value: &lt; 2.2e-16</code></pre></li>
<li><p>[3 puntos] Estime ahora los errores robustos a heteroscedasticidad del tipo HC1. ¿Qué cambia y por qué en la interpretación de la relación entre la prueba de aptitud y el examen?</p>
<p><em>El coeficiente estimado es el mismo. La fórmula empleada para calcular la varianza es una en forma de sándwich, que toma en cuenta la posible heterocedasticidad. El error estándar es apromximadamente 5% más grande, 0.076.</em></p>
<pre class="r"><code>coeftest(m.mco, vcov = vcovHC(m.mco, type = &quot;HC1&quot;))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 10.939796   0.985476 11.1010   &lt;2e-16 ***
## iq_verb      2.486350   0.075871 32.7709   &lt;2e-16 ***
## sex          2.422279   0.288525  8.3954   &lt;2e-16 ***
## minority    -0.037006   0.612455 -0.0604   0.9518    
## repeatgr    -4.408605   0.448615 -9.8271   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre></li>
<li><p>[2 puntos] Estime la ecuación de calificación usando MCO y efectos fijos de escuela. ¿Qué resuelve este procedimiento?</p>
<p><em>Al incluir efectos fijos a nivel escuela controlamos por características no observadas a nivel escuela. Estas diferencias se incorporan en el modelo como desplazamientos de la ordenada al origen. Este procedimiento no considera la agrupación de los errores.</em></p>
<pre class="r"><code>summary(m.mco.ef &lt;- lm(langpost ~ iq_verb + sex + minority + repeatgr + factor(schoolnr), data=data.examen))</code></pre>
<pre><code>## 
## Call:
## lm(formula = langpost ~ iq_verb + sex + minority + repeatgr + 
##     factor(schoolnr), data = data.examen)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -24.8792  -3.6779   0.2729   4.0985  19.6755 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)         12.50218    1.54290   8.103 8.89e-16 ***
## iq_verb              2.25997    0.07093  31.860  &lt; 2e-16 ***
## sex                  2.41900    0.26850   9.009  &lt; 2e-16 ***
## minority             0.23262    0.71306   0.326 0.744280    
## repeatgr            -4.43503    0.40938 -10.834  &lt; 2e-16 ***
## factor(schoolnr)2   -8.29681    2.67144  -3.106 0.001923 ** 
## factor(schoolnr)10  -7.28322    3.06053  -2.380 0.017412 *  
## factor(schoolnr)12  -4.56719    2.06924  -2.207 0.027407 *  
## factor(schoolnr)15  -7.41516    2.54948  -2.909 0.003669 ** 
## factor(schoolnr)16   2.53410    2.54854   0.994 0.320173    
## factor(schoolnr)18  -6.80332    1.81757  -3.743 0.000187 ***
## factor(schoolnr)21  -0.53872    1.99103  -0.271 0.786746    
## factor(schoolnr)24   4.20444    1.81839   2.312 0.020862 *  
## factor(schoolnr)26  -0.36076    1.96000  -0.184 0.853984    
## factor(schoolnr)27  -5.46850    1.87909  -2.910 0.003649 ** 
## factor(schoolnr)29   3.19018    2.35758   1.353 0.176147    
## factor(schoolnr)33  -0.34896    2.84408  -0.123 0.902359    
## factor(schoolnr)35   1.59577    2.08305   0.766 0.443718    
## factor(schoolnr)36  -3.99135    1.83661  -2.173 0.029873 *  
## factor(schoolnr)38   3.05382    1.75466   1.740 0.081931 .  
## factor(schoolnr)40   0.09036    1.67651   0.054 0.957022    
## factor(schoolnr)41  -2.94006    2.13296  -1.378 0.168226    
## factor(schoolnr)42  -4.99799    2.10828  -2.371 0.017845 *  
## factor(schoolnr)44  -1.49855    2.04728  -0.732 0.464268    
## factor(schoolnr)47  -5.73732    2.52469  -2.272 0.023156 *  
## factor(schoolnr)48  -1.83632    2.25583  -0.814 0.415717    
## factor(schoolnr)49  -4.14690    2.41410  -1.718 0.085979 .  
## factor(schoolnr)52  -3.60350    1.87627  -1.921 0.054918 .  
## factor(schoolnr)54   2.91142    1.72017   1.693 0.090691 .  
## factor(schoolnr)55   1.49383    1.73053   0.863 0.388111    
## factor(schoolnr)57   0.79682    1.80093   0.442 0.658210    
## factor(schoolnr)60  -1.79256    1.83760  -0.975 0.329426    
## factor(schoolnr)61   0.39402    1.89130   0.208 0.834990    
## factor(schoolnr)62   2.39062    1.88568   1.268 0.205016    
## factor(schoolnr)65   5.66979    1.85875   3.050 0.002314 ** 
## factor(schoolnr)66   1.09325    2.28956   0.477 0.633058    
## factor(schoolnr)67  -5.59969    1.78486  -3.137 0.001728 ** 
## factor(schoolnr)68  -1.22319    1.90619  -0.642 0.521140    
## factor(schoolnr)76  -1.14607    2.02551  -0.566 0.571577    
## factor(schoolnr)78   0.20198    1.99000   0.101 0.919167    
## factor(schoolnr)79   2.10981    2.10998   1.000 0.317463    
## factor(schoolnr)80   3.31569    1.87290   1.770 0.076810 .  
## factor(schoolnr)86   1.45319    1.81855   0.799 0.424322    
## factor(schoolnr)87  -0.20740    1.88076  -0.110 0.912200    
## factor(schoolnr)88   1.25972    2.35398   0.535 0.592604    
## factor(schoolnr)90   4.45169    2.06677   2.154 0.031356 *  
## factor(schoolnr)94   3.05367    2.05599   1.485 0.137621    
## factor(schoolnr)95  -0.76530    1.94512  -0.393 0.694027    
## factor(schoolnr)97   1.48348    1.98190   0.749 0.454232    
## factor(schoolnr)98  -1.40960    1.89893  -0.742 0.457977    
## factor(schoolnr)101  4.26255    1.83026   2.329 0.019955 *  
## factor(schoolnr)103 -4.54699    3.34961  -1.357 0.174775    
## factor(schoolnr)106 -2.63664    2.33290  -1.130 0.258518    
## factor(schoolnr)107 -4.50332    1.99406  -2.258 0.024023 *  
## factor(schoolnr)108 -1.87255    2.44170  -0.767 0.443222    
## factor(schoolnr)109 -4.40708    1.87743  -2.347 0.018995 *  
## factor(schoolnr)110  3.08759    1.99160   1.550 0.121215    
## factor(schoolnr)111  1.23407    1.94637   0.634 0.526125    
## factor(schoolnr)112 -0.24997    2.67934  -0.093 0.925678    
## factor(schoolnr)115 -0.13189    1.72755  -0.076 0.939152    
## factor(schoolnr)116 -0.96627    1.93966  -0.498 0.618421    
## factor(schoolnr)118 -4.19606    2.42987  -1.727 0.084335 .  
## factor(schoolnr)119 -0.37636    2.21669  -0.170 0.865195    
## factor(schoolnr)121 -3.16182    2.35853  -1.341 0.180196    
## factor(schoolnr)123  2.76021    3.34170   0.826 0.408902    
## factor(schoolnr)124  3.69157    1.89801   1.945 0.051909 .  
## factor(schoolnr)125  1.79787    1.76911   1.016 0.309622    
## factor(schoolnr)130  5.61009    2.16507   2.591 0.009629 ** 
## factor(schoolnr)132  6.28128    1.87651   3.347 0.000830 ***
## factor(schoolnr)136  3.87282    2.03048   1.907 0.056610 .  
## factor(schoolnr)137  4.40378    1.95919   2.248 0.024693 *  
## factor(schoolnr)141  1.14473    1.90727   0.600 0.548441    
## factor(schoolnr)142  5.13270    1.82046   2.819 0.004855 ** 
## factor(schoolnr)147  7.45698    1.85918   4.011 6.26e-05 ***
## factor(schoolnr)148  2.09875    1.74675   1.202 0.229682    
## factor(schoolnr)149  2.53123    1.88015   1.346 0.178351    
## factor(schoolnr)150  1.56758    1.80115   0.870 0.384221    
## factor(schoolnr)151  0.81632    1.83732   0.444 0.656871    
## factor(schoolnr)152  6.20977    1.99227   3.117 0.001852 ** 
## factor(schoolnr)155  4.06995    1.69447   2.402 0.016394 *  
## factor(schoolnr)156  1.03255    2.21442   0.466 0.641061    
## factor(schoolnr)159  2.82606    1.71234   1.650 0.099006 .  
## factor(schoolnr)160  3.52358    1.80662   1.950 0.051261 .  
## factor(schoolnr)161  5.47210    1.70824   3.203 0.001378 ** 
## factor(schoolnr)164  4.69601    1.81787   2.583 0.009853 ** 
## factor(schoolnr)167  3.85744    1.79977   2.143 0.032201 *  
## factor(schoolnr)170  1.92686    1.78368   1.080 0.280143    
## factor(schoolnr)175  4.18579    2.10407   1.989 0.046785 *  
## factor(schoolnr)176  6.59497    1.83757   3.589 0.000339 ***
## factor(schoolnr)177  1.42445    1.99027   0.716 0.474249    
## factor(schoolnr)179 -7.16566    2.82071  -2.540 0.011143 *  
## factor(schoolnr)182  1.78603    2.41396   0.740 0.459456    
## factor(schoolnr)183  0.85895    1.70516   0.504 0.614499    
## factor(schoolnr)184  0.99731    1.74622   0.571 0.567974    
## factor(schoolnr)188 -0.58465    2.19526  -0.266 0.790015    
## factor(schoolnr)189  3.22324    1.98341   1.625 0.104287    
## factor(schoolnr)192 -1.80905    2.55487  -0.708 0.478973    
## factor(schoolnr)193  6.24675    2.21572   2.819 0.004857 ** 
## factor(schoolnr)195  0.62668    1.90527   0.329 0.742247    
## factor(schoolnr)196  2.79306    1.77499   1.574 0.115735    
## factor(schoolnr)197  1.31643    1.90977   0.689 0.490700    
## factor(schoolnr)198 -2.54503    2.66624  -0.955 0.339919    
## factor(schoolnr)199 -4.10925    1.69994  -2.417 0.015719 *  
## factor(schoolnr)204  0.98462    1.81798   0.542 0.588149    
## factor(schoolnr)206  3.79180    2.28001   1.663 0.096446 .  
## factor(schoolnr)209  2.44276    1.83923   1.328 0.184272    
## factor(schoolnr)210 -0.40756    2.02750  -0.201 0.840706    
## factor(schoolnr)212  1.37659    1.80057   0.765 0.444637    
## factor(schoolnr)214 -3.50270    1.85506  -1.888 0.059136 .  
## factor(schoolnr)215  2.42072    2.21308   1.094 0.274155    
## factor(schoolnr)216  3.25053    2.68121   1.212 0.225516    
## factor(schoolnr)217  3.17962    2.55021   1.247 0.212604    
## factor(schoolnr)218  5.14348    1.79490   2.866 0.004203 ** 
## factor(schoolnr)219  5.03571    2.10754   2.389 0.016962 *  
## factor(schoolnr)222  1.27021    1.81917   0.698 0.485106    
## factor(schoolnr)224  0.16178    2.15792   0.075 0.940246    
## factor(schoolnr)226  0.43861    2.55025   0.172 0.863464    
## factor(schoolnr)227  3.11551    1.95897   1.590 0.111895    
## factor(schoolnr)228  7.82086    1.88038   4.159 3.32e-05 ***
## factor(schoolnr)231  4.99594    1.87985   2.658 0.007928 ** 
## factor(schoolnr)233 -3.62877    2.44368  -1.485 0.137700    
## factor(schoolnr)234  4.45798    2.13964   2.084 0.037322 *  
## factor(schoolnr)235  4.18463    2.35443   1.777 0.075653 .  
## factor(schoolnr)237  1.69607    2.06447   0.822 0.411422    
## factor(schoolnr)240 -0.21368    2.21446  -0.096 0.923139    
## factor(schoolnr)241  1.82195    1.83630   0.992 0.321219    
## factor(schoolnr)242  5.11955    2.27771   2.248 0.024698 *  
## factor(schoolnr)243  4.71818    2.54942   1.851 0.064352 .  
## factor(schoolnr)244 -0.81472    2.15710  -0.378 0.705695    
## factor(schoolnr)246  3.94809    2.21570   1.782 0.074911 .  
## factor(schoolnr)249  0.18111    1.81893   0.100 0.920695    
## factor(schoolnr)250 -0.69331    2.06691  -0.335 0.737332    
## factor(schoolnr)252 -0.36370    2.27756  -0.160 0.873140    
## factor(schoolnr)256 -8.25432    2.35336  -3.507 0.000462 ***
## factor(schoolnr)258 -8.24124    2.68111  -3.074 0.002140 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 6.186 on 2152 degrees of freedom
## Multiple R-squared:  0.5557, Adjusted R-squared:  0.528 
## F-statistic: 20.08 on 134 and 2152 DF,  p-value: &lt; 2.2e-16</code></pre></li>
<li><p>[5 puntos] Estime la ecuación de calificación usando MCO y con errores agrupados a nivel escuela (sin efectos fijos de escuela). ¿Qué resuelve este procedimiento?</p>
<p><em>Al estimar los errores agrupados y robustos a heterocedasticidad se toma en cuenta la correlación que existe en los errores dentro de cada escuela. Los errores agrupados estimados con la opción cluster asumen correlación de errores dentro del grupo, pero no entre grupos. Con respecto a las partes b. y c., el error estándar asociado al tiempo dedicado a la tarea es aproximadamente 20% mayor. Este es un ejemplo típico en el que los errores agrupados están inflados con respecto a los errores de MCO clásicos y los errores robustos.</em></p>
<p><em>Nota: es posible que los errores agrupados sean menores que los errores de MCO. Para ver eso, considere un modelo simple con datos agrupados de la forma siguiente: <span class="math display">\[y_{ig=\alpha+\beta x_{ig}+u_{ig}}\]</span> donde <span class="math inline">\(x_{ig}\)</span> es un regresor escalar.</em></p>
<p><em>Se asume que el tamaño promedio de los grupos es <span class="math inline">\(\bar{N}_g\)</span>. Moulton (1990) muestra que el error estándar de MCO esta sesgado hacia abajo por una cantidad igual a la raíz de <span class="math inline">\(\tau \approx 1 +\rho_x \rho_u (\bar{N}_g-1)\)</span>, donde <span class="math inline">\(\rho_x\)</span> es la correlación dentro de los grupos de <span class="math inline">\(x\)</span> y <span class="math inline">\(\rho_u\)</span> es la correlación dentro de los grupos de los errores. Esto implica que para obtener el error correcto que toma en cuenta la agrupación hay que multiplicar el error de MCO por la raíz de <span class="math inline">\(\tau\)</span>. Sin embargo, note que dependiendo del signo y la magnitud de <span class="math inline">\(\rho_x\)</span> y <span class="math inline">\(\rho_u\)</span>, la raíz de <span class="math inline">\(\tau\)</span> puede llegar a ser menor que 1 y, por tanto, el error agrupado puede llegar a ser menor que el de MCO. <span class="math inline">\(\tau\)</span> se conoce como el factor de Moulton y puede ser extendido para un modelo más complicado. La intuición funciona de manera similar para un modelo más comlicado: todo depende de las correlaciones entre grupos de los regresores y la correlación de los errores.</em></p>
<pre class="r"><code>coef_test(m.mco, vcov = &quot;CR1S&quot;, cluster = data.examen$schoolnr)</code></pre>
<pre><code>##         Coef. Estimate     SE   t-stat  d.f. p-val (Satt) Sig.
## 1 (Intercept)   10.940 1.2559   8.7109  95.2       &lt;0.001  ***
## 2     iq_verb    2.486 0.0899  27.6464  94.5       &lt;0.001  ***
## 3         sex    2.422 0.2846   8.5110 110.0       &lt;0.001  ***
## 4    minority   -0.037 0.8547  -0.0433  20.0        0.966     
## 5    repeatgr   -4.409 0.3958 -11.1381  81.8       &lt;0.001  ***</code></pre></li>
<li><p>[5 puntos] Estime la ecuación de calificación usando MCO, variables indicadoras de escuela y con errores agrupados a nivel escuela. ¿Qué resuelve este procedimiento?</p>
<p><em>Al controlar por características no observadas de las escuelas empleando efectos fijos por escuela y además estimando los errores que toman en cuenta la estructura agrupada de los errores obtenemos un coeficiente estimado de 2.26, pero con un error estándar mayor, 0.0915.</em></p>
<pre class="r"><code>coef_test(m.mco.ef, vcov = &quot;CR1S&quot;, cluster = data.examen$schoolnr)</code></pre>
<pre><code>##                   Coef. Estimate     SE  t-stat  d.f. p-val (Satt) Sig.
## 1           (Intercept)  12.5022 1.1668  10.715  86.2      &lt; 0.001  ***
## 2               iq_verb   2.2600 0.0915  24.695  94.0      &lt; 0.001  ***
## 3                   sex   2.4190 0.2836   8.529 106.5      &lt; 0.001  ***
## 4              minority   0.2326 0.7172   0.324  32.0      0.74778     
## 5              repeatgr  -4.4350 0.4083 -10.862  82.3      &lt; 0.001  ***
## 6     factor(schoolnr)2  -8.2968 0.3795 -21.863  42.8      &lt; 0.001  ***
## 7    factor(schoolnr)10  -7.2832 0.4270 -17.058  32.6      &lt; 0.001  ***
## 8    factor(schoolnr)12  -4.5672 0.4565 -10.005  37.0      &lt; 0.001  ***
## 9    factor(schoolnr)15  -7.4152 0.4211 -17.611  31.8      &lt; 0.001  ***
## 10   factor(schoolnr)16   2.5341 0.4252   5.960  30.8      &lt; 0.001  ***
## 11   factor(schoolnr)18  -6.8033 0.4225 -16.101  30.3      &lt; 0.001  ***
## 12   factor(schoolnr)21  -0.5387 0.4188  -1.286  31.1      0.20787     
## 13   factor(schoolnr)24   4.2044 0.4187  10.042  31.3      &lt; 0.001  ***
## 14   factor(schoolnr)26  -0.3608 0.4253  -0.848  31.4      0.40275     
## 15   factor(schoolnr)27  -5.4685 0.4170 -13.113  30.4      &lt; 0.001  ***
## 16   factor(schoolnr)29   3.1902 0.4536   7.033  34.2      &lt; 0.001  ***
## 17   factor(schoolnr)33  -0.3490 0.4205  -0.830  30.8      0.41305     
## 18   factor(schoolnr)35   1.5958 0.2760   5.783  31.3      &lt; 0.001  ***
## 19   factor(schoolnr)36  -3.9913 0.4175  -9.560  30.5      &lt; 0.001  ***
## 20   factor(schoolnr)38   3.0538 0.4171   7.322  31.0      &lt; 0.001  ***
## 21   factor(schoolnr)40   0.0904 0.4264   0.212  32.0      0.83352     
## 22   factor(schoolnr)41  -2.9401 0.2796 -10.515  33.9      &lt; 0.001  ***
## 23   factor(schoolnr)42  -4.9980 0.4168 -11.992  31.1      &lt; 0.001  ***
## 24   factor(schoolnr)44  -1.4985 0.3315  -4.520  30.9      &lt; 0.001  ***
## 25   factor(schoolnr)47  -5.7373 0.2712 -21.152  81.0      &lt; 0.001  ***
## 26   factor(schoolnr)48  -1.8363 0.2637  -6.963  47.5      &lt; 0.001  ***
## 27   factor(schoolnr)49  -4.1469 0.2037 -20.359  44.2      &lt; 0.001  ***
## 28   factor(schoolnr)52  -3.6035 0.3986  -9.041  34.0      &lt; 0.001  ***
## 29   factor(schoolnr)54   2.9114 0.4389   6.634  33.4      &lt; 0.001  ***
## 30   factor(schoolnr)55   1.4938 0.4230   3.532  32.1      0.00127   **
## 31   factor(schoolnr)57   0.7968 0.3384   2.354  32.6      0.02472    *
## 32   factor(schoolnr)60  -1.7926 0.3208  -5.588  30.8      &lt; 0.001  ***
## 33   factor(schoolnr)61   0.3940 0.3533   1.115  33.0      0.27283     
## 34   factor(schoolnr)62   2.3906 0.4618   5.177  34.7      &lt; 0.001  ***
## 35   factor(schoolnr)65   5.6698 0.4298  13.192  31.4      &lt; 0.001  ***
## 36   factor(schoolnr)66   1.0933 0.4601   2.376  40.1      0.02237    *
## 37   factor(schoolnr)67  -5.5997 0.4214 -13.289  31.4      &lt; 0.001  ***
## 38   factor(schoolnr)68  -1.2232 0.4360  -2.806  32.6      0.00841   **
## 39   factor(schoolnr)76  -1.1461 0.4266  -2.687  31.5      0.01142    *
## 40   factor(schoolnr)78   0.2020 0.4157   0.486  30.7      0.63054     
## 41   factor(schoolnr)79   2.1098 0.4214   5.006  32.2      &lt; 0.001  ***
## 42   factor(schoolnr)80   3.3157 0.3850   8.613  31.6      &lt; 0.001  ***
## 43   factor(schoolnr)86   1.4532 0.4241   3.427  30.8      0.00175   **
## 44   factor(schoolnr)87  -0.2074 0.4152  -0.500  31.8      0.62085     
## 45   factor(schoolnr)88   1.2597 0.4166   3.024  31.5      0.00493   **
## 46   factor(schoolnr)90   4.4517 0.4252  10.470  33.8      &lt; 0.001  ***
## 47   factor(schoolnr)94   3.0537 0.3997   7.641  41.1      &lt; 0.001  ***
## 48   factor(schoolnr)95  -0.7653 0.3455  -2.215  32.8      0.03383    *
## 49   factor(schoolnr)97   1.4835 0.3802   3.902  30.6      &lt; 0.001  ***
## 50   factor(schoolnr)98  -1.4096 0.3875  -3.637  33.2      &lt; 0.001  ***
## 51  factor(schoolnr)101   4.2626 0.3876  10.997  31.6      &lt; 0.001  ***
## 52  factor(schoolnr)103  -4.5470 0.4170 -10.903  85.5      &lt; 0.001  ***
## 53  factor(schoolnr)106  -2.6366 0.2861  -9.217  35.1      &lt; 0.001  ***
## 54  factor(schoolnr)107  -4.5033 0.4439 -10.144  33.2      &lt; 0.001  ***
## 55  factor(schoolnr)108  -1.8726 0.4256  -4.399  30.5      &lt; 0.001  ***
## 56  factor(schoolnr)109  -4.4071 0.2769 -15.917  31.5      &lt; 0.001  ***
## 57  factor(schoolnr)110   3.0876 0.4218   7.319  31.6      &lt; 0.001  ***
## 58  factor(schoolnr)111   1.2341 0.3645   3.386  33.6      0.00182   **
## 59  factor(schoolnr)112  -0.2500 0.4327  -0.578  32.0      0.56748     
## 60  factor(schoolnr)115  -0.1319 0.4179  -0.316  30.4      0.75445     
## 61  factor(schoolnr)116  -0.9663 0.4511  -2.142  37.6      0.03872    *
## 62  factor(schoolnr)118  -4.1961 0.3504 -11.975  31.3      &lt; 0.001  ***
## 63  factor(schoolnr)119  -0.3764 0.4254  -0.885  33.3      0.38261     
## 64  factor(schoolnr)121  -3.1618 0.4610  -6.858  35.0      &lt; 0.001  ***
## 65  factor(schoolnr)123   2.7602 0.2742  10.065  79.0      &lt; 0.001  ***
## 66  factor(schoolnr)124   3.6916 0.3958   9.328  32.1      &lt; 0.001  ***
## 67  factor(schoolnr)125   1.7979 0.3552   5.061  33.4      &lt; 0.001  ***
## 68  factor(schoolnr)130   5.6101 0.4385  12.793  37.4      &lt; 0.001  ***
## 69  factor(schoolnr)132   6.2813 0.4103  15.310  33.7      &lt; 0.001  ***
## 70  factor(schoolnr)136   3.8728 0.4443   8.717  35.6      &lt; 0.001  ***
## 71  factor(schoolnr)137   4.4038 0.4166  10.572  31.2      &lt; 0.001  ***
## 72  factor(schoolnr)141   1.1447 0.4237   2.702  33.3      0.01076    *
## 73  factor(schoolnr)142   5.1327 0.4232  12.128  32.3      &lt; 0.001  ***
## 74  factor(schoolnr)147   7.4570 0.4345  17.162  31.5      &lt; 0.001  ***
## 75  factor(schoolnr)148   2.0988 0.4457   4.709  34.9      &lt; 0.001  ***
## 76  factor(schoolnr)149   2.5312 0.4209   6.014  30.9      &lt; 0.001  ***
## 77  factor(schoolnr)150   1.5676 0.4150   3.777  31.5      &lt; 0.001  ***
## 78  factor(schoolnr)151   0.8163 0.4195   1.946  31.6      0.06058    .
## 79  factor(schoolnr)152   6.2098 0.4255  14.593  32.5      &lt; 0.001  ***
## 80  factor(schoolnr)155   4.0699 0.4161   9.782  31.0      &lt; 0.001  ***
## 81  factor(schoolnr)156   1.0325 0.4308   2.397  31.4      0.02266    *
## 82  factor(schoolnr)159   2.8261 0.4024   7.023  31.8      &lt; 0.001  ***
## 83  factor(schoolnr)160   3.5236 0.2557  13.779  38.4      &lt; 0.001  ***
## 84  factor(schoolnr)161   5.4721 0.3829  14.293  32.8      &lt; 0.001  ***
## 85  factor(schoolnr)164   4.6960 0.4234  11.091  30.5      &lt; 0.001  ***
## 86  factor(schoolnr)167   3.8574 0.4182   9.224  30.6      &lt; 0.001  ***
## 87  factor(schoolnr)170   1.9269 0.4180   4.610  31.1      &lt; 0.001  ***
## 88  factor(schoolnr)175   4.1858 0.4077  10.267  35.7      &lt; 0.001  ***
## 89  factor(schoolnr)176   6.5950 0.4201  15.700  31.0      &lt; 0.001  ***
## 90  factor(schoolnr)177   1.4245 0.4199   3.392  30.5      0.00194   **
## 91  factor(schoolnr)179  -7.1657 0.2125 -33.715  41.9      &lt; 0.001  ***
## 92  factor(schoolnr)182   1.7860 0.2113   8.451  34.4      &lt; 0.001  ***
## 93  factor(schoolnr)183   0.8589 0.3729   2.303  30.5      0.02826    *
## 94  factor(schoolnr)184   0.9973 0.3839   2.598  33.5      0.01383    *
## 95  factor(schoolnr)188  -0.5847 0.3032  -1.928  33.1      0.06242    .
## 96  factor(schoolnr)189   3.2232 0.3779   8.530  32.1      &lt; 0.001  ***
## 97  factor(schoolnr)192  -1.8091 0.4496  -4.023  37.0      &lt; 0.001  ***
## 98  factor(schoolnr)193   6.2468 0.4308  14.501  32.7      &lt; 0.001  ***
## 99  factor(schoolnr)195   0.6267 0.4210   1.488  31.7      0.14650     
## 100 factor(schoolnr)196   2.7931 0.4324   6.459  35.0      &lt; 0.001  ***
## 101 factor(schoolnr)197   1.3164 0.4603   2.860  34.6      0.00713   **
## 102 factor(schoolnr)198  -2.5450 0.3200  -7.953  34.3      &lt; 0.001  ***
## 103 factor(schoolnr)199  -4.1093 0.2785 -14.757  32.7      &lt; 0.001  ***
## 104 factor(schoolnr)204   0.9846 0.4150   2.373  31.2      0.02399    *
## 105 factor(schoolnr)206   3.7918 0.4353   8.710  32.0      &lt; 0.001  ***
## 106 factor(schoolnr)209   2.4428 0.4206   5.807  32.5      &lt; 0.001  ***
## 107 factor(schoolnr)210  -0.4076 0.4372  -0.932  32.1      0.35823     
## 108 factor(schoolnr)212   1.3766 0.4185   3.289  31.1      0.00250   **
## 109 factor(schoolnr)214  -3.5027 0.2946 -11.888  32.9      &lt; 0.001  ***
## 110 factor(schoolnr)215   2.4207 0.4178   5.794  30.4      &lt; 0.001  ***
## 111 factor(schoolnr)216   3.2505 0.4410   7.372  32.5      &lt; 0.001  ***
## 112 factor(schoolnr)217   3.1796 0.4449   7.147  32.2      &lt; 0.001  ***
## 113 factor(schoolnr)218   5.1435 0.3697  13.911  62.4      &lt; 0.001  ***
## 114 factor(schoolnr)219   5.0357 0.4230  11.905  30.3      &lt; 0.001  ***
## 115 factor(schoolnr)222   1.2702 0.4156   3.056  31.8      0.00451   **
## 116 factor(schoolnr)224   0.1618 0.4265   0.379  31.1      0.70703     
## 117 factor(schoolnr)226   0.4386 0.4260   1.030  32.3      0.31078     
## 118 factor(schoolnr)227   3.1155 0.4252   7.328  30.6      &lt; 0.001  ***
## 119 factor(schoolnr)228   7.8209 0.4246  18.420  31.2      &lt; 0.001  ***
## 120 factor(schoolnr)231   4.9959 0.4204  11.882  31.2      &lt; 0.001  ***
## 121 factor(schoolnr)233  -3.6288 0.4254  -8.531  33.5      &lt; 0.001  ***
## 122 factor(schoolnr)234   4.4580 0.3188  13.983  32.4      &lt; 0.001  ***
## 123 factor(schoolnr)235   4.1846 0.4228   9.897  31.6      &lt; 0.001  ***
## 124 factor(schoolnr)237   1.6961 0.4150   4.087  31.1      &lt; 0.001  ***
## 125 factor(schoolnr)240  -0.2137 0.4258  -0.502  31.8      0.61922     
## 126 factor(schoolnr)241   1.8219 0.4171   4.368  30.5      &lt; 0.001  ***
## 127 factor(schoolnr)242   5.1196 0.4241  12.072  31.1      &lt; 0.001  ***
## 128 factor(schoolnr)243   4.7182 0.4237  11.135  32.9      &lt; 0.001  ***
## 129 factor(schoolnr)244  -0.8147 0.4161  -1.958  31.0      0.05931    .
## 130 factor(schoolnr)246   3.9481 0.4392   8.989  32.1      &lt; 0.001  ***
## 131 factor(schoolnr)249   0.1811 0.4219   0.429  31.6      0.67064     
## 132 factor(schoolnr)250  -0.6933 0.4225  -1.641  33.8      0.11005     
## 133 factor(schoolnr)252  -0.3637 0.4199  -0.866  30.4      0.39321     
## 134 factor(schoolnr)256  -8.2543 0.4278 -19.295  31.9      &lt; 0.001  ***
## 135 factor(schoolnr)258  -8.2412 0.4220 -19.529  33.5      &lt; 0.001  ***</code></pre></li>
</ol>
</div>
<div id="pregunta-5" class="section level1">
<h1>Pregunta 5</h1>
<p>Considere la base <em>capital_trabajo.csv</em>. Con una función de producción Cobb-Douglas las participaciones del capital y el trabajo en el valor de la producción se pueden estimar usando una regresión lineal. En algunas aplicaciones es de interés conocer el cociente de las participaciones estimadas.</p>
<ol style="list-style-type: lower-alpha">
<li><p>[10 puntos] Usando 500 repeticiones bootstrap estime el error estándar del cociente capital-trabajo. Para ello realice el siguiente procedimiento:</p>
<ol style="list-style-type: lower-roman">
<li>Genere una matriz vacía de 500 filas para coleccionar sus relaciones estimadas.</li>
<li>En cada una de las repeticiones obtenga una muestra con remplazo a partir de la muestra original.</li>
<li>Estime por MCO los coeficientes sobre el log del capital y el log del trabajo. La variable dependiente es el log del valor de la producción. Calcule el cociente de los coeficientes estimados. Guarde el cociente en la matriz.</li>
<li>Repita ii. y iii. 500 veces.</li>
<li>Calcule la desviación estándar de los cocientes estimados.</li>
</ol>
<p><em>En cada repetición bootstrap debemos estimar el siguiente modelo y obtener el ratio de los coeficientes:</em></p>
<pre class="r"><code>data.kl&lt;-read_csv(&quot;./capital_trabajo.csv&quot;,
                  locale = locale(encoding = &quot;latin1&quot;)) </code></pre>
<pre><code>## Rows: 100 Columns: 6</code></pre>
<pre><code>## -- Column specification --------------------------------------------------------
## Delimiter: &quot;,&quot;
## dbl (6): id, capital, trabajo, lcapital, ltrabajo, lvalor</code></pre>
<pre><code>## 
## i Use `spec()` to retrieve the full column specification for this data.
## i Specify the column types or set `show_col_types = FALSE` to quiet this message.</code></pre>
<pre class="r"><code>summary(m1 &lt;- lm(lvalor ~ lcapital + ltrabajo, data=data.kl))</code></pre>
<pre><code>## 
## Call:
## lm(formula = lvalor ~ lcapital + ltrabajo, data = data.kl)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.53523 -0.25678  0.03835  0.26003  0.49631 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 10.56478    0.05303  199.24   &lt;2e-16 ***
## lcapital     0.38502    0.03072   12.53   &lt;2e-16 ***
## ltrabajo     0.66108    0.02813   23.50   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.2999 on 97 degrees of freedom
## Multiple R-squared:  0.8768, Adjusted R-squared:  0.8742 
## F-statistic: 345.1 on 2 and 97 DF,  p-value: &lt; 2.2e-16</code></pre>
<p><em>La rutina bootstrap es la siguiente:</em></p>
<pre class="r"><code>set.seed(120)
B=500
obs &lt;- nrow(data.kl)

#Inicializamos el vector donde guardaremos los beta estimados
beta &lt;- data.frame(beta=matrix(ncol = 1, nrow = B))

for (i in 1:B)
{
  data.b &lt;-data.kl[sample(nrow(data.kl),obs, replace = TRUE),]

  #Corremos regresión

  m&lt;-lm(lvalor ~ lcapital + ltrabajo, data=data.b)

  #Guardamos en cada entrada el ratio estimado
  beta[i,1] &lt;- as.numeric(m$coefficients[2] / m$coefficients[3])
}

#El error estimado es simplemente la desviación estándar de los B estadísticos estimados
sd(beta$beta)</code></pre>
<pre><code>## [1] 0.05090312</code></pre>
<p><em>El error estándar estimado es de 0.0509.</em></p></li>
<li><p>[10 puntos] Compruebe que su cálculo aproxima el error estándar obtenido con el Método Delta. Para ello, después de estimar la ecuación del valor de la producción con la muestra original puede usar la función <em>deltaMethod</em> del paquete <em>car</em>.</p>
<p><em>Si usamos el método Delta para calcular el error estándar de la combinación no lineal, obtenemos algo muy parecido.</em></p>
<pre class="r"><code>deltaMethod(m1, &quot;lcapital/ltrabajo&quot;)</code></pre>
<pre><code>##                   Estimate       SE    2.5 % 97.5 %
## lcapital/ltrabajo 0.582406 0.051923 0.480639 0.6842</code></pre></li>
</ol>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Propuesta <a href="https://stackoverflow.com/questions/49282083/xtsum-command-for-r">aquí</a>.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
