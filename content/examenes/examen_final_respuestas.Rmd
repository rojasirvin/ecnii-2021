---
title: "Respuestas al examen parcial"
summary: " "
weight: 2
type: book
toc: false
---

```{r setup, include=FALSE}
library(tidyverse)
library(janitor)
library(knitr)
library(kableExtra)
library(car)
library(AER)
knitr::opts_chunk$set(collapse = TRUE)
```

## Respuestas

## Pregunta 1

Considere una variable aleatoria $x$ que se distribuye de acuerdo a la función de densidad gamma, con parámetros $\alpha$ (forma) y $\lambda$ (tasa): $$ f(x | \alpha, \lambda) = \frac{1}{\Gamma(\alpha)}\lambda^{\alpha}x^{\alpha-1}e^{-\lambda x}$$ Se asume $\alpha>0$, $\lambda>0$ y $x_i>0$. La función $\Gamma(a)$ se define como $\Gamma(a)=(a-1)!$, aunque en este problema puede trabajar simplemente dejando la función indicada.

a. [5 puntos] Escriba la log verosimilitud de la observación $i$.

    *Simplemente tomamos logaritmos a la densidad: $$\begin{align}l(x_i | \alpha, \lambda)&=\ln(l(x | \alpha, \lambda))=\ln(\Gamma(\alpha)^{-1})+\alpha\ln(\lambda)+(\alpha-1)\ln(x)-\lambda x \\ &=-\ln(\Gamma(\alpha))+\alpha\ln(\lambda)+(\alpha-1)\ln(x)-\lambda x \end{align}$$*

a. [5 puntos] Escriba la log verosimilitud del problema para la muestra de tamaño $N$.

    *Sabemos que $\mathcal{L}(x | \alpha, \lambda)=\sum_i \mathcal{l}(x | \alpha, \lambda)$. Entonces, debido al supuesto de distribución idéntica:* $$\begin{align}\mathcal{L}(x | \alpha, \lambda)&=\sum_i \left(-\ln(\Gamma(\alpha))+\alpha\ln(\lambda)+(\alpha-1)\ln(x_i)-\lambda x\right) \\ &= n(\alpha\ln(\lambda)-\ln(\Gamma(\alpha)))+(\alpha-1)\sum_i\ln(x_i) - \lambda \sum x_i\end{align}$$
    
    
a. [5 puntos] Obtenga las condiciones de primer orden para la maximización del problema de log verosimilitud. En el resto del problema, no necesita calcular explícitamente la derivada $\frac{d \ln (\Gamma(\alpha))}{d \alpha}$, basta con dejarla indicada donde corresponda.

    *Derivamos con respecto a $\alpha$ y $\lambda$:*
    
    $$\frac{\partial\mathcal{L}}{\partial \alpha} = n\ln(\lambda) -n \frac{d\ln (\Gamma(\alpha))}{d \alpha} + \sum_i \ln(x_i)=0$$
    
    $$\frac{\partial\mathcal{L}}{\partial \lambda} = \frac{n\alpha}{\lambda}-\sum_i x_i = 0$$
    
a. [5 puntos] Usando la condición de primer orden $\frac{\partial\mathcal{L}}{\partial \lambda}=0$ derive una expresión para $\lambda$ en términos de $\alpha$ y las $x_i$.

    *Usando la segunda condición, $\sum_i x_i = n\alpha / \lambda$. Por tanto, $\lambda=\alpha/ \bar{x}$, donde $\bar{x}$ es la media muestral.*

a. [5 puntos] Sustituya la expresión anterior para $\lambda$ en términos de $\alpha$ y las $x_i$ en la condición de primer orden $\frac{\partial\mathcal{L}}{\partial \alpha}=0$ y obtenga una expresión que represente el problema de optimización que debe ser solucionado de manera numérica.

    *Sustituimos  $\lambda=\alpha/$ en la primera condición:*     $$\begin{align} &n\ln\left(\frac{\alpha}{\bar{x}}\right) -n \frac{d \ln (\Gamma(\alpha))}{d \alpha} + \sum_i \ln(x_i) \\ &=n\left(\ln(\alpha)-\ln(\bar{x}) - \frac{d \ln (\Gamma(\alpha))}{d \alpha} - \bar{\ln(x)}\right) =0\end{align}$$ *Podemos usar software para encontrar el valor de $\alpha$ que hace que esta condición se cumple y sustituir dicho valor en la expresión para $\lambda$ y obtener así $[\hat{\alpha}_{MV},\hat{\lambda}_{MV}]$*
    
a. [5 puntos] Obtenga la matriz de información de Fisher.

    *Basta con obtener la segunda derivada de cada condición y la derivada cruzada:*
    $$\frac{\partial^2\mathcal{L}}{\partial \alpha^2}=-n \frac{d^2 \ln (\Gamma(\alpha))}{d \alpha^2}$$
     
    $$\frac{\partial^2\mathcal{L}}{\partial \lambda^2} = -\frac{n\alpha}{\lambda^2} $$
      
    $$\frac{\partial^2\mathcal{L}}{\partial \alpha \lambda}=\frac{n}{\lambda}$$
      
    *Y entonces armamos la matriz de información:*
      
    $$I(\alpha,\lambda)=n\left(\begin{matrix} \frac{d^2 \ln (\Gamma(\alpha))}{d \alpha^2} & -\frac{1 }{\lambda} \\ -\frac{1 }{\lambda} & \frac{\alpha}{\lambda^2} \end{matrix}\right)$$
    
# Pregunta 2

Construya un breve argumento para los siguientes dos puntos, ambos independientes entre sí. Puede auxiliarse o no de ecuaciones, aunque lo más importante son sus argumentos conceptuales. Explique si esta afirmación es cierta o falsa y por qué.

a. [10 puntos] En un modelo de regresión lineal como sigue: $$y_i=a + X_i b + e_i$$ con $y_i$ continua y $K$ regresores exógenos, es necesario que los errores sean normales e iid para que el estimador de MCO de $b$ sea consistente.

    *Ninguna de las condiciones es necesaria cuando usamos teoría asintótica. El estimador de MCO puede expresarse como $\hat{b}=b+(\frac{1}{N}X'X)^{-1}(\frac{1}{N}X'e)$. Por tanto, si podemos aplicar una LGN a $(\frac{1}{N}X'X)$ y un TLC a $(\frac{1}{N}X'e)$, el estimador de MCO tendrá una distribución asintótica normal, centrado en $b$ y con una varianza que dependerá de la varianza de los errores, independientemente de cuál sea su distribución.*
    
    *Respecto a la parte 'idéntica' en el supuesto de iid, sabemos que podemos construir una matriz robusta a heterocedasticidad para considerar el caso en que la varianza de los errores sea distinta entre las $i$ , conservando la distribución asintótica normal.*
    
    *Hasta aquí lo que hemos visto en el curso y con lo que otorgo crédito completo. Sin embargo, tampoco es necesaria la parte 'independiente' en iid. La matriz de varianzas robusta puede incorporar la correlación entre observaciones en sección cruzada y en el tiempo. Esto lo veremos con más detalle cuando hablemos de errores agrupados.*

a. [10 puntos] Considere el problema de explicar el gasto de los hogares en automóviles usando una serie de características $X_i$. Muchos hogares tendrán gasto en autmóviles igual a cero. Explique las similitudes y diferencias entre el estimador tobit para muestras censuradas y el estimador de dos etapas de Heckman aplicado a dicho problema.

    *Tenemos un problema de censura y sabemos que MCO ignora este hecho. Un estimador de tobit o de Heckman sí lo reconocen. El estimador tobit se obtiene al espeficar la verosimilitud del problema, considerando una masa de observaciones agrupadas en gasto igual a cero. El estimador de Heckman en dos etapas toma en cuenta la censura al considerar el problema como uno de variable omitida, donde la variable omitida es la probabilidad de observar un gasto positivo (dada por el inverso de la razón de Mills). Ambos estimadores se basan en modelos que asumen errores normales (y heterocedásticos, al menos los vistos en clase).*
    
    *La mayor diferencia es que el estimador de tobit se base en un modelo en que la censura y el gasto observado tiene un mismo proceso generador de datos. En cambio, el modelo de Heckman especifíca explícitamente dos procesos: uno de participación y uno de gasto realizado.*


# Pregunta 3

Considere los datos en el archivo *ingresos_iv.csv*, usados en la tarea 2. De acuerdo con Card (1995), una variable que indique si los individuos vivían cerca de una universidad cuando eran niños, **nearc4**, puede ser empleada como instrumento de la educación en una regresión de retornos a la educación. 

a. [5 puntos] Suponga que, por alguna razón, solo tiene acceso a una variable **nearc2**, que indica si el individuo vivía cerca de una universidad que tiene solo carreras técnicas y/o educación para el trabajo. En Estados Unidos esto se conoce como *two-year colllege* o universidad de dos años. Estime el mismo modelo de variables instrumentales que en la tarea 2 para explicar el logaritmo del salario (**lwage**) en función de la educación **educ** y los siguientes controles: **exper**, **expersq**, **black**, **south**, **smsa**, **reg661**, **reg662**, **reg663**, **reg664**, **reg665**, **reg666**, **reg667**, **reg668** y **smsa66**, tratando a la educación como endógena, y usando **nearc2** como instrumento.

    *Estimamos por variables instrumentales*:

    ```{r tidy=TRUE, include=T,echo=T,collapse=TRUE,warning=FALSE, message=FALSE}
data.ingresos <-read_csv("./ingresos_iv.csv",
                         locale = locale(encoding = "latin1"))
    
mvi <- ivreg(lwage ~ educ + exper + expersq + black + south + smsa + reg661 + reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66  |
               . - educ + nearc2,
               data=data.ingresos)

summary(mvi)
    ```

a. [5 puntos] ¿Qué condiciones debe cumplir **nearc2** para ser un instrumento? ¿Cuáles considera que son posibles violaciones a estas condiciones?

    *Vivir cerca de una universidad de dos años cuando se era niño debe afectar el número de años que los individuos pasan en la escuela (primera etapa) y no pertenecer a la ecuación de salarios (exclusión).*
    
    *No hay una sola respuesta correcta sobre posibles violaciones. Quiero leer sus argumentos.*

a. [5 puntos] Interprete el coeficiente asociado a la educación en la ecuación estructural.

    *Un año más de educación incrementa el salario ¡en 29%!. Sin embargo, este efecto no es estimado precisamente. No podemos rechazar la $H0$ de que el efecto sea de hecho cero.*
    
a. [5 puntos] Estime la primera etapa e interprete el coeficiente asociado a **nearc2**.

    *La primera etapa es:*

    ```{r tidy=TRUE, include=T,echo=T,collapse=TRUE,warning=FALSE, message=FALSE}
mpe <- lm(educ ~ nearc2 + exper + expersq + black + south + smsa + reg661 + reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66, 
          data=data.ingresos)

summary(mpe)
    ```

    *Los individuos que viven cerca de una universidad de dos años tienen 0.12 años más de educación. Sin embargo, este coeficiente no es estadísticamente significativo con $p=0.11709$.*

a. [5 puntos] ¿Qué puede concluir respecto a la validez de la primera etapa?

    *De la regresión por VI podemos obtener un diagnóstico:*
    
    ```{r tidy=TRUE, include=T,echo=T,collapse=TRUE,warning=FALSE, message=FALSE}
summary(mvi, diagnostics = TRUE)
```

    *El diagnóstico inclue una prueba de instrumentos débiles. No es posible rechazar la $H0$ de que el instrumento es débil con $p=0.11709$, la misma probabilidad con la que no rechazamos la $H0$ de que el coeficiente asociado a **nearc2** es cero en la primera etapa. Se concluye que no evidencia que respalde que **nearc2** y **educ** están correlacionadas.*

a. [5 puntos] ¿Qué concluye respecto a la estrategia alternativa de usar **nearc2** como instrumento de la educación para identificar el efecto causal de la educación sobre los ingresos?

    *Aún cuando conceptualmente la variable **nearc2** pudiera tener las mismas características que **nearc4** para funcionar como instrumento, empíricamente **nearc2** no funciona. La primera etapa muestra que no existe correlación entre **nearc2** y la variable de educación. Por tanto, no tenemos primera etapa y, como consecuencia, el coeficiente sobre educación en la ecuación estructural no está identificado.*


    
# Pregunta 4

Considere los mismos datos que en la pregunta 3, pero ahora olvidemos por un rato el problema de identificar el rendimiento de la educación. Considere un modelo de probabilidad no lineal por medio del cual queremos conocer la probabilidad de que un individuo esté en el grupo con un log del salario mayor al 80% de todos los individuos en la muestra (esto es, que pertence al 20% de los individuos con mayor log del salario). Note que esta variable no está en el archivo, debe construirla. Supongamos además que solo se observan las características **black** y **south**, así como un test de habilidad **kww**. Usaremos un modelo logit para estimar esta relación.

a. [5 puntos] Estime el modelo logit de la probabilidad de estar en el grupo del 20% de individuos con mayor log del salario, en función de **black**, **south**, **kww** y una constante.

    ```{r tidy=TRUE, include=T,echo=T,collapse=TRUE,warning=FALSE, message=FALSE}

a <- quantile(data.ingresos$lwage, .8)
    
data.ingresos <- data.ingresos %>% 
  mutate(top_ingreso = ifelse(lwage > a, 1, 0))
    
logit <- glm(top_ingreso ~ kww +  black + south,
          data=data.ingresos,
          family = binomial(link = "logit"))

summary(logit)
    ```

a. [5 puntos] ¿Cómo se interpreta el coeficiente asociado a **kww**?

    *Un incremento de una unidad en el puntaje del test medido en **kww** incrementa en 0.093 el log de la razón de momios.*

a. [5 puntos] ¿Cómo cambia el riesgo relativo cuando el test de habilidad **kww** se incrementa en una unidad?

    *Simplemente calculamos $exp(\hat{\beta}_{kww})$*:

    ```{r tidy=TRUE, include=T,echo=T,collapse=TRUE,warning=FALSE, message=FALSE}
exp(coef(logit))
    ```
a. [5 puntos] Explique cómo estimaría el error estándar del cambio en el riesgo relativo cuando **kww** se incrementa en una unidad. No es necesario que realice dicha estimación.

    *Una foma de hacerlo es usando el método delta. Sabemos la distribución asintótica del vector $\hat{\beta}$ y su matriz de varianzas estimada, $\hat{V}(\hat{\beta})$. La magnitud del cambio que queremos evaluar está dada por $g(\hat{\beta})=exp(\hat{\beta})$. Esta nueva variable aleatoria tendrá como varianza $h(\beta)'\hat{V}(\hat{\beta})h(\beta)$, con $h(\beta)=g'(\beta)$. La raíz cuadrada de la entrada correspondiente a **kww** en la matriz de varianzas será el error estándar de $exp(\hat{\beta}_{kww})$.*
    
    *En R, podemos hacer esto fácilmente con la función deltaMethod, aunque esto ya no era necesario en el examen:*

    ```{r tidy=TRUE, include=T,echo=T,collapse=TRUE,warning=FALSE, message=FALSE}
deltaMethod(logit, "exp(kww)")
    ```
    
    *Una forma alternativa de estimar el error estándar es con bootstrap, que veremos más adelante en el curso.*