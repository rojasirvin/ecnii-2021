---
title: "Modelos multinomiales"
author: "Irvin Rojas"
institute: "CIDE"
date: "9 de septimebre de 2021"
mathspec: true
output:
  xaringan::moon_reader:
    seal: false
    chakra: "https://remarkjs.com/downloads/remark-latest.min.js"
    lib_dir: libs
    nature:
      highlightLines: true
      countIncrementalSlides: false
      titleSlideClass: ["middle", "center"]
      ratio: "16:9"
      beforeInit: ["https://platform.twitter.com/widgets.js", "libs/cols_macro.js"]
      navigation:
      scroll: false
    css: [default, "libs/cide.css", metropolis-fonts, "https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap-grid.min.css", "https://use.fontawesome.com/releases/v5.7.2/css/all.css", "https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"]
include-before:
- '\newcommand\myeq{\stackrel{\mathclap{\normalfont\mbox{s}}}{~}}'

---
class: title-slide

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.path = "figures/")

library(tidyverse)
library(janitor)
library(sandwich)
library(modelsummary)
library(nnet)
xfun::pkg_load2(c('base64enc', 'htmltools', 'mime'))
```

```{css, echo = FALSE}
.huge .remark-code { /*Change made here*/
  font-size: 200% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 60% !important;
}
```


.title[
# Sesión 7. Modelos multinomiales
]
.subtitle[
## Econometría II
]
.author[
### Irvin Rojas <br> [rojasirvin.com](https://www.rojasirvin.com/) <br> [<i class="fab fa-github"></i>](https://github.com/rojasirvin) [<i class="fab fa-twitter"></i>](https://twitter.com/RojasIrvin) [<i class="ai ai-google-scholar"></i>](https://scholar.google.com/citations?user=FUwdSTMAAAAJ&hl=en)
]

.affiliation[
### Centro de Investigación y Docencia Económicas <br> División de Economía
]

---
# Agenda
  
1. Estudiaremos la generalización de los modelos de variable categórica a cuando las opciones son más de dos

1. Mostraremos las propiedades asintóticas de los estimadores de MV para este tipo de modelos


---

class: inverse, middle, center

# Modelos multinomiales

---

# Modelos multinomiales

- Pensemos en un caso más general donde $y$ toma el valor de $j$ si la $j$ésima alternativa se escoge:

$$p_j=P(y=j)\quad j=1,\ldots,m$$

- Esto se puede ver como un problema de $m$ decisiones binarias:

$$
y_i=
\begin{cases}
1 \quad\text{si }y=j \\
0 \quad\text{si }y\neq j \\
\end{cases}
$$

--

- La densidad multinomial para un individuo es

$$f(y)=p_1^{y_1}\times\ldots\times p_m^{y_m}=\prod_j p_j^{y_j}$$

donde $p_{ij}=P(y_i=j)=F_j(X_i,\beta)$

---

# Verosimilitud

- Para una muestra de $N$ observaciones independientes, la log verosimilitud es:

$$\mathcal{L}_n=\sum_i\sum_j y_{ij}\ln(p_{ij})$$

con $p_{ij}=F_j(x_i,\beta)$

--

- Las condiciones de primer orden están dadas por:

$$\frac{\partial \mathcal{L}}{\partial\beta}=\sum_i\sum_j\frac{y_{ij}}{p_{ij}}\frac{\partial p_{ij}}{\partial\beta}=0$$
---

# Distribución asintótica

- Noten que la distribución es necesariamente multinomial, por lo que $E(y_{ij})=p_{ij}$ y el estimador de MV será consistente

--

- Además, de forma análoga al modelo de probabilidad no lineal, la correcta especificación garantiza que la distribución asintótica esté dada por el negativo del inverso de la matriz de información:

$$\hat{\beta}\stackrel{a}{\sim}\mathcal{N}\left(\beta_0, \left(\sum_i\sum_j\frac{1}{p_{ij}}\frac{\partial p_{ij}}{\partial\beta}\frac{\partial p_{ij}}{\partial\beta'}-\frac{\partial^2p_{ij}}{\partial\beta\partial\beta'}\Bigg|_{\beta_0} \right)^{-1}\right)$$

--

- Mientras estemos en un contexto de sección cruzada con observaciones independientes, no es necesario recurrir a una matriz robusta
--

- De nuevo, con observaciones independientes sobre $i$, no es necesario implementar una matriz de sándwich

---

# Regresores variantes entre alternativas

- Podemos pensar la forma en que las $X$ entran en el modelo en dos extremos

- Pensemos en que cada alternativa tiene sus propias características

$$x_i=[x_{i1}'\;x_{i2}'\;\ldots\;x_{im}']'$$
- Por tanto, la probabilidad de escoger la alternativa $j$ es:

$$p_{ij}=F_{ij}(x_i,\beta)=F_j(x_{i1}'\beta,\ldots,x_{im}\beta)$$

- Cuando esto sucede, las $\beta$s son constantes entre alternativas

- Por ejemplo, los precios o la calidad en un modelo de elección de un producto financiero

- El modelo más común para este tipo de problemas es el **logit condicional**

---

# Regresores invariantes entre alternativas

- Por ejemplo, las características socioeconómicas de los consumidores que eligen entre varios tipos de cerveza

$$F_j(x_i,\beta)=F_j(x_i'\beta,\ldots x_i'\beta_m)$$

- En este caso, los parámetros son distintos para cada alternativa:

$$\beta=[\beta_1'\;\beta_2'\;\ldots\;\beta_m']$$

- Se realiza una normalización $\beta_1=0$

- Por ejemplo, el ingreso o la edad del individuo que selecciona un producto

- Una aplicación de este caso es el **logit multinomial**

---

# Distinción entre tipo de modelos

- La distinción es importante para la implementación de los modelos

- La mayoría de los paquetes estadísticos requieren arreglar los datos de formas distintas dependiendo de qué modelo vaya a estimarse

---

# Regresores variantes e invariantes entre alternativas

- En la práctica, ambos tipos de regresores pueden estar disponibles y ser de interés

- Se recomienda entonces escribir el modelo como de **alternativas variantes** (por ejemplo, condicional logit)

- Siempre es posible escribir el modelo de **alternativas invariantes** como uno de **alternativas variantes**

---

# Regresores variantes e invariantes entre alternativas

- Tomemos el vector $x_i$ de dimensión $K \times 1$ (las características de un individuo)

- Definamos $x_{ij}$ un vector de $Km\times 1$ de ceros excepto en el $j$-ésimo bloque, que será $x_i$

- Y definamos $\beta=[0'\;\beta_2'\;\ldots \beta_m']'$, donde $\beta_{1}=0$

- Así, $x_i'\beta_j=x_{ij}'\beta$

- Los regresores se incluyen como interacciones con variables dummy para cada alternativa

---

class: inverse, middle, center

# Tipos de modelos multinomiales

---

# Tipos de modelos multinomiales

- En el curso, tendremos la siguiente convención de nombres:

  - Logit condicional: regresores variantes entre alternativas
  
  - Logit multinomial: regresores invariantes entre alternativas


--

- En la práctica, podemos tener regresores de ambos tipos:

  - Logit mixto
  


---

# Ejemplo: pesca 


| | $y = 1$|  $y = 2$| $y = 3$ | $y = 4$ | Todos $y$ |
|---- |:---: |:---: |:---: | :---:|:---: |
|Var. explicativa   | Playa | Puerto | Privado | Barco | 
|Ingreso (mUSD) |4.052| 3.387 | 4.654 | 3.881 | 4.099 | 
|Precio playa | 36 | 31 | 138 | 121 | 103 |
|Precio puerto ($)  | 36 | 31  | 138  | 121 | 103| 
|Precio privado ($) | 98  | 82 | 42 | 45 | 55|
|Precio barco ($) | 125|  110| 71| 75|  84 |
|Tasa de pesca playa | 0.28 | 0.26 | 0.21 | 0.25  | 0.24 |
|Tasa de pesca puerto | 0.22  | 0.20 | 0.13 | 0.16 | 0.16 |
|Tasa de pesca privado  |0.16 | 0.15 | 0.18 | 0.18 | 0.17 |
|Tasa de pesca barco | 0.52 | 0.50 | 0.65  | 0.69 | 0.63 |
|Probabilidad | 0.113 | 0.151 | 0.354 | 0.38 | 1.000 |
|N | 134| 178| 418| 452| 1182|

---

# Ejemplo: pesca 

- El precio de cada tipo y la tasa de pesca varían entre alternativas

- Parece haber una relación inversa entre el precio y la decisión

- La relación no es tan clara en cuanto a la tasa


--

- Además parece que la gente con mayor ingreso se mueve progresivamente hacia la derecha en la tabla anterior

---

# Logit condicional

- Supongamos que los regresores varían entre alternativas:

$$p_{ij}=\frac{exp(x_{ij}'\beta)}{\sum_{l=1}^m exp(x_{il}'\beta)},\quad j=1\ldots,m$$
- Esta expresión nos da la probabilidad de que el $i$-ésimo individuo escoja la alternativa $j$

- Las probabilidades están entre 0 y 1 y suman 1

- En el **caso del logit condicional**, el signo del coeficiente $\beta$ es directamente interpretable

---

# Logit condicional en el problema de pesca

- En el caso del ejemplo de pesca, el logit condicional quedaría así:

$$p_{ij}=\frac{exp(\beta_P P_{ij}+\beta_C C_{ij})}{\sum_{k=1}^4 exp(\beta_P P_{ik}+\beta_C C_{ik})},\quad j=1\ldots,4$$
- Lo que estimamos es el efecto en la probabilidad de escoger una alternativa cuando cambia el precio o cuando cambia la tasa de pesca

- En el caso del logit condicional, estaremos seguros que un aumento en el precio disminuye la probabilidad de elegir un modo de pesca

- Y lo contrario se concluye para la tasa de pesca

---

# Ejemplo: resultados del modelo de pesca 

| Regresor |  Tipo|  Coeficiente |  LC|  LMN |  Mixto | 
| ----- |  | :-----: | :-----: |  :-----: |  :-----:|  :-----: | 
 | Precio (P) |  Variante |  $\beta_P$ |  −0.021 |  –| −0.025 | 
 | Tasa de pesca (C) |  Variante |  $\beta_C$ |  0.953 |  –| 0.358 | 
 | Constante  | Invariante  | $\alpha_1$ : Playa  | –| 0.0 |  0.0 | 
 |  | | $\alpha_2$ : Puerto |  – |0.814 |  0.778 | 
 |  | | $\alpha_3$ : Privado |  –| 0.739 |  0.527 | 
 |  | | $\alpha_4$: Barco  | – |1.341  | 1.694 | 
 | Ingreso (I) |  Invariante |  $\beta_{I1}$ : Playa | –| 0.0  | 0.0 | 
 |  | | $\beta_{I2}$ : Puerto  | –  | −0.143 |  −0.128 | 
 |  | | $\beta_{I3}$ : Privado  | –  | 0.092 |  0.089 | 
 |  | | $\beta_{I4}$ : Barco |– | −0.032  | −0.033 | 


---

# Logit multinomial

- La probablidad está dada por:

$$p_{ij}=\frac{exp(x_{i}'\beta_j)}{\sum_{l=1}^m exp(x_{i}'\beta_l)},\quad j=1\ldots,m$$

- Se impone la restricción de un $\beta_0$

- La interpretación de los parámetros es más complicada

- Un coeficiente estimado positivo no se traduce directamente como un incremento en la probabilidad de escoger una alternativa

- La interpretación de los coeficientes se da con respecto a la categoría base

---

# Logit multinomial en el problema de pesca

- El ingreso no varía entre alternativas

- En este caso el modelo logit multinomial queda como:

$$p_{ij}=\frac{exp(\alpha_j+\beta_{Ij}I_i)}{\sum_{k=1}^4exp(\alpha_k+\beta_{Ik}I_i)},\quad j=1\ldots,4$$

- Aquí normalizamos $\alpha_1=\beta_{I1}=0$

- En este caso, no podemos decir que un incremento en un regresor se traduzca en un incremento en la probabilidad de escoger cierta alternativa

- La interpretación en este modelo se da con respecto a la cateogría omitida, en este caso playa

---

# Modelo mixto

- Permite incorporar regresores variantes e invariantes entre alternativas

- Se especifica:

$$p_{ij}=\frac{exp(x_{ji}'\beta+w_i'\gamma_j)}{\sum_{l=1}^m exp(x_{il}'\beta+w_i'\gamma_l)},\quad j=1\ldots,m$$

donde $x_{ij}$ son características que varían entre alternativas mientras que las $w_i$ no varían entre alternativas

---

# Modelo mixto en el problema de pesca

- En nuestro ejemplo de pesca:

$$p_{ij}=\frac{exp(\beta_P P_{ij}+\beta_C C_{ij}+\alpha_j+\beta_{Ij}I_i)}{\sum_{k=1}^4exp(\beta_p P_{ik}+\beta_C C_{ik}+\alpha_k+\beta_{Ik}I_i)},\quad j=1\ldots,4$$
- Una forma de implementar el modelo es con variables dummy para convertirlo en un logit condicional:

$$p_{ij}=\frac{exp(\beta_P P_{ij}+\beta_C C_{ij}+\sum_{l=1}^4(\alpha_jd_{ijl}+\beta_{Il}I_{ijl}))}{\sum_{k=1}^4exp(\beta_p P_{ik}+\beta_C C_{ik}+\sum_{l=1}^4(\alpha_ld_{ijl}+\beta_{Il}I_{ijl}))},\quad j=1\ldots,4$$
- $d_{ijl}$ es igual a 1 si $j=l$ y 0 en otro caso

- $d_{ijl}I_i=dI_{ijl}$ toma el valor del ingreso si $j=l$

- Es correr la regresión sobre $P_{ij}$, $C_{ij}$, $d_{ij2}$, $d_{ij3}$, $d_{ij4}$, $dI_{ij2}$, $dI_{ij3}$ y $dI_{ij4}$

---

# Ejemplo: resultados del modelo de pesca 

| Regresor |  Tipo|  Coeficiente |  LC|  LMN |  Mixto | 
| ----- |  | :-----: | :-----: |  :-----: |  :-----:|  :-----: | 
 | Precio (P) |  Variante |  $\beta_P$ |  −0.021 |  –| −0.025 | 
 | Tasa de pesca (C) |  Variante |  $\beta_C$ |  0.953 |  –| 0.358 | 
 | Constante  | Invariante  | $\alpha_1$ : Playa  | –| 0.0 |  0.0 | 
 |  | | $\alpha_2$ : Puerto |  – |0.814 |  0.778 | 
 |  | | $\alpha_3$ : Privado |  –| 0.739 |  0.527 | 
 |  | | $\alpha_4$: Barco  | – |1.341  | 1.694 | 
 | Ingreso (I) |  Invariante |  $\beta_{I1}$ : Playa  | –| 0.0  | 0.0 | 
 |  | | $\beta_{I2}$ : Puerto  | –  | −0.143 |  −0.128 | 
 |  | | $\beta_{I3}$ : Privado | –  | 0.092 |  0.089 | 
 |  | | $\beta_{I4}$ : Barco |– | −0.032  | −0.033 | 

---

class: inverse, center, middle

# Interpretación de parámetros

---

# Efectos marginales en el logit condicional

- Estamos interesados en el cambio en la probabilidad de que la opción $j$ sea escogida cuando $x_{ik}$ cambia marginalmente:

$$\frac{\partial p_{ij}}{\partial x_{ik}}=p_{ij}(d_{ijk}-p_{ik})\beta$$
donde $d_{ijk}=1$ si $j=k$

--

- Noten que en este caso el signo del coeficiente sí nos dice la dirección del efecto marginal

- Si $\beta$ es positivo, un incremento en el componente correspondiente del regresor $k$ incrementa la probabilidad de que la opción $k$ se escogida, y reduce la probabilidad de las otras opciones

- Por ejemplo, el coeficiente sobre el precio estimado en la columna CL de la Tabla 15.2 en CT es negativo, por lo que el efecto marginal de un cambio en el precio de, digamos, pescar desde la playa, también lo será

---

# Efectos marginales en el logit multinomial

- Estamos interesados en el cambio en la probabilidad de que la opción $j$ sea escogida cuando $x_{i}$ cambia marginalmente:

$$\frac{\partial p_{ij}}{\partial x_{i}}=p_{ij}(\beta_j-\bar{\beta}_i)$$
donde $\bar{\beta}_i=\sum_l p_{il}\beta_l$ es el promedio de los $\beta_l$ ponderado por las probabilidades

- Claramente, el signo de $\beta_j$ no determina el signo del efecto marginal

- Una práctica común es estimar el promedio de efectos marginales:

$$\frac{1}{N}\sum_i\frac{\partial p_{ij}}{\partial x_{i}}=\frac{1}{N}\sum_ip_{ij}(\beta_j-\bar{\beta}_i)$$

---
# Riesgo relativo en el logit multinomial


- En el caso del logit multinomial, consideremos la probabilidad de escoger $j$, dado que se observan $j$ o $k$

- Esto se puede escribir como

$$
\begin{aligned}
P(y=j|y=\{j,k\})&=\frac{p_j}{p_j+p_k} \\
&=\frac{exp(x'\beta_j)}{exp(x'\beta_j)+exp(x'\beta_k)} \\
&=\frac{exp(x'(\beta_j-\beta_k))}{1+exp(x'(\beta_j-\beta_k))}
\end{aligned}
$$
- Noten que esto es como tener un logit con coeficiente $(\beta_j-\beta_k)$

---

# Riesgo relativo en el logit multinomial

- Al normalizar una categoría, digamos $\beta_1=0$, podemos comparar la alternativa $j$ con la 1

$$
\begin{aligned}
P(y_i=j|y_i=\{j,1\})=\frac{exp(x_i'\beta_j)}{1+exp(x_i'\beta_j)}
\end{aligned}
$$

- Es decir, podemos ver el problema como una serie de comparaciones binarias entre la opción $j$-ésima y la 1

---
# Riesgo relativo en el logit multinomial

- Otra manera de interpretar los resultados es comparando la probabilidad de escoger la categoría $j$ con la 1:

$$
\frac{P(y_i=j)}{P(y_i=1)}=exp(x_i'\beta_j)
$$
- Como lo mostramos con el logit, $exp(\beta_{jr})$ es el cambio en el riesgo relativo cuando el regresor $r$-ésimo cambia en una unidad

- La categoría omitida puede ser escogida a conveniencia, prefiriendo la que permita una mejor interpretación

---

# Riesgo relativo en el logit condiconal

- Para el caso del logit condicional (hay regresores variantes entre alternativas) podemos expresar la probabilidad de escoger $j$ dado que se escoge $j$ o $k$ como:


$$
\begin{aligned}
P(y_i=j|y_i=\{j,k\})=\frac{exp((x_{ij}-x_{ik})'\beta)}{1+exp((x_{ij}-x_{ik})'\beta)}
\end{aligned}
$$


---

class: inverse, center, middle

# De nuevo los datos de juguete de pesca

---

# En R

- Asegúrense de tener instalados los siguientes paquetes:

  - *nnet*: más usado para logit multinomial, pero también para muchas otras cosas más
  
  - *mlogit*: un poco más confuso de usar, más usado para el logit condicional
  
  - *sandwich*: para trabajar con matríces de varianzas y construir versiones robustas

---

# Ejemplo: logit multinomial

.pull-left[
- Datos de Herriges & Kling (1999) usados y provistos por Cameron & Trivedi (2005)

- La función *multinom* de la librería *nnet*

```{r echo=TRUE, message=F, results='hide'}
data_fishing<-read_csv(
  "./fishing_data.csv",
  locale = locale(encoding = "latin1")) %>% 
  clean_names() %>% 
  mutate(income=income/1000)

mmultilogit_1 <- multinom(
  mode ~ income,
  data = data_fishing)
```
]

.pull-right[

Notemos que obtenemos los coeficientes correspondientes de la tabla 15.2 de CT
```{r echo=TRUE, message=F}
summary(mmultilogit_1)
```
]

---

# Ejemplo: logit multinomial

- La tabla 15.2 dice que todos los coeficientes, excepto $\beta_{I4}$ son estadísticamente significativos al 5%

- Si queremos los valores $p$

```{r echo=TRUE, message=F}

z <- summary(mmultilogit_1)$coefficients/summary(mmultilogit_1)$standard.errors

pv <- (1 - pnorm(abs(z)))*2 
pv
```


---

# Nota cultural

- El paquete usado para estimar los logit multinomial es *nnet*, que es una abreviatura para *neural networks*

- Las *redes neuronales*, una aplicación en constante desarrollo del *aprendizaje automatizado* pueden emplearse, entre muchas otras cosas, para problemas de clasificación

- [Acá](https://towardsdatascience.com/classification-using-neural-networks-b8e98f3a904f) pueden ver un post al respecto

--

- En cierto sentido, nuestros modelos multinomiales son problemas de clasificación

---

# Ejemplo: logit condicional

- Lo verán en el laboratorio

---

# Próxima sesión

- Comenzaremos con conteo

  - CT capítulo 20
  
---

class: center, middle

Presentación creada usando el paquete [**xaringan**](https://github.com/yihui/xaringan) en R.

El *chakra* viene de [remark.js](https://remarkjs.com), [**knitr**](http://yihui.org/knitr), y [R Markdown](https://rmarkdown.rstudio.com).

Material de clase en versión preliminar.

**No reproducir, no distribuir, no citar.**