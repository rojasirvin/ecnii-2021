<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Estimadores M</title>
    <meta charset="utf-8" />
    <meta name="author" content="Irvin Rojas" />
    <script src="libs/header-attrs-2.9/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="libs/cide.css" type="text/css" />
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap-grid.min.css" type="text/css" />
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.7.2/css/all.css" type="text/css" />
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: title-slide



.title[
# Clase 3. Estimadores M
]
.subtitle[
## Econometría II
]
.author[
### Irvin Rojas &lt;br&gt; [rojasirvin.com](https://www.rojasirvin.com/) &lt;br&gt; [&lt;i class="fab fa-github"&gt;&lt;/i&gt;](https://github.com/rojasirvin) [&lt;i class="fab fa-twitter"&gt;&lt;/i&gt;](https://twitter.com/RojasIrvin) [&lt;i class="ai ai-google-scholar"&gt;&lt;/i&gt;](https://scholar.google.com/citations?user=FUwdSTMAAAAJ&amp;hl=en)
]

.affiliation[
### Centro de Investigación y Docencia Económicas &lt;br&gt; División de Economía
]

---
# Agenda
  
1. Introducir las propiedades de los estimadores M

1. Introducir el concepto de máxima verosimilitud

---

# Estimadores no lineales

- Los estimadores no lineales son funciones no lineales de la variable dependiente

- Pueden surgir por:
   - Variable dependiente categórica o de conteo
   
   - Censura
   
   - Truncamiento

- Presentaremos resultados asintóticos para los estimadores M

- Queremos que ustedes comprendan la intuición de las pruebas, más que memorizar las pruebas mismas

- Y que logren relacionar la teoría con lo que realizan de forma inmediata lo que realizan los paquetes estadísticos


---

class: inverse, middle, center

# Estimadores extremos

---

# Estimadores extremos

- Nos centraremos por ahora en secciones cruzadas

- Para cada observación, vemos una variable dependiente escalar `\(y_i\)` y un vector de regresores `\(x_i\)`

- Un vector de datos entonces es `\((y_i,x_i)\)`

- Podemos acomodar los datos en una matrix `\((y,X)\)`

--

- Existe un vector de parámetros verdadero `\(\theta_0\)`, que es el valor de `\(\theta\)` que da origen a los datos

- Buscamos estimar el vector de parámetros `\(\theta=(\theta_1,\ldots,\theta_q)'\)`

- Consideremos la función objetivo estocástica `\(Q_N(\theta)=Q_N(y,x,\theta)=\frac{1}{N}\sum_i q(y_i,x_i,\theta)\)`, donde `\(q(\cdot)\)` es una función escalar

- Un **estimador extremo** `\(\hat{\theta}\)` es un estimador que maximiza `\(Q_N\)`

- Hay muchos estimadores M, dependiendo de la forma de `\(q(\cdot)\)`, entre ellos, los estimadores de máxima verosimilitud y los estimadores de mínimos cuadrados no lineales

---

# Ejemplo: estimador de máxima verosimilitud

- El problema de máxima verosimilitud consiste en estimar el vector de parámetros para `\(\theta_0\)` que maximice la probabilidad de observar los datos

- La función de masa de probabilidad o densidad `\(f(y,X|\theta)\)` es una función del parámetro `\(\theta\)` y los datos `\((y,X)\)`

- A esto se le llama **función de verosimilitud** y frecuentemente se le denota `\(L_N(\theta|y,X)\)`

- Maximizar `\(L_N\)` es equivalente a maximizar  `\(\mathcal{L}_N(\theta)=\ln(L_N(\theta))\)` 

- Cuando trabajamos con secciones cruzadas con observaciones independientes, `\(f(y|X,\theta)=\Pi_i f(y_i|x_i,\theta)\)`

- Y entonces, la función de log verosimilitud se define como:

`$$Q_N(\theta)=N^{-1}\mathcal{L}(\theta)=N^{-1}\sum_i\ln f(y_i|x_i,\theta)$$`
---

# Ejemplo: estimador de máxima verosimilitud

- El **estimador de máxima verosimilitud** es el estimador que maximiza la función de log verosimilitud

- Formalmente, se conoce como el **estimador de máxima verosimilitud condicional** al máximo local que satisface la condición de primer orden:

`$$\frac{1}{N}\frac{\partial \mathcal{L}_N(\theta)}{\partial \theta }=\frac{1}{N}\sum_i\frac{\partial \ln f(y_i|x_i,\theta)}{\partial \theta}=0$$`
- El adjetivo de **condicional** se debe a que el estimador se basa en la densidad de `\(y\)` dado `\(x\)`, pero comúnmente se emplea solo el término de estimador de máxima verosimilitud

- Al vector gradiente de primeras derivadas parciales `\(s(\theta)=\frac{\mathcal{L}_N(\theta)}{\partial \theta}\)` se le conoce como **vector score**

- Al score evaluado en `\(\theta_0\)` se le conoce como **score eficiente**

---

# Propiedades asintóticas de los estimadores M

- De forma general, un estimador extremo es un máximo local, calculado como la solución de las condiciones de primer orden :

`$$\frac{\partial Q_N(\theta)}{\partial \theta}\Bigg|_{\hat{\theta}}=0$$`
- Hacemos énfasis en el máximo local pues es lo que se distribuye asintóticamente normal

- Noten que `\(Q_N\)` se definió de forma que es un promedio muestral, de forma análoga a la suma de residuales cuadrados

- Nuestro objetivo es establecer las propiedades asintóticas en términos de

  - Consistencia
  
  - Distribución asintótica
  
---
  
# Consistencia de estimadores M

- La función objetivo `\(Q_N(\theta)\)` converge en probabilidad a la función límite `\(Q_0(\theta)\)` cuando `\(N\to \infty\)`

- Entonces, el máximo local de `\(Q_N(\theta)\)` y `\(Q_0(\theta)\)` deben ocurrir en valores de `\(\theta\)` cada vez más cercanos

- Dado que por definición `\(\hat{\theta}_{MV}\)` maximiza `\(Q_N(\theta)\)`, entonces `\(\hat{\theta}_{MV}\)` converge en probabilidad a `\(\theta_0\)`, asumiendo que `\(\theta_0\)` maximiza `\(Q_0(\theta)\)`

---
# Consistencia de estimadores M

**Consitencia del máximo local** (Amemiya, 1985, adaptado por CT, 2005)

- Supongamos que:

  1. El espacio de parámetros `\(\Theta\)` es un subconjunto abierto de `\(R^q\)`
  
  1. `\(Q_N(\theta)\)` es una una [función medible](https://www.math.ucdavis.edu/~hunter/measure_theory/measure_notes_ch3.pdf) de los datos para todo `\(\theta \in \Theta\)` y `\(\partial Q_N(\theta)/\partial\theta\)` existe y es continua en una vecindad de `\(\theta_0\)`
  
  1. La función objetivo `\(Q_N(\theta)\)` converge uniformemente en probabilidad a `\(Q_0\)` en una vecindad abierta de `\(\theta_0\)` y `\(Q_0(\theta)\)` tiene un único máximo local en `\(\theta_0\)`
  
- Entonces, la solución a `\(\partial Q_N(\theta)/\partial \theta =0\)` es consistente para `\(\theta_0\)`

---

# Consistencia de estimadores M

- La condición clave es la 3. y nos dice que le máximo local de `\(Q_N(\theta)\)` debe ocurrir en `\(\theta_0\)`

- Los primeros dos supuestos se cumplirán en la mayoría de las aplicaciones que usaremos en el curso

- El paso más importante será obtener la probabilidad límite de `\(Q_N(\theta)\)`

- Para ello recurrimos a LGN porque `\(Q_N(\theta)\)` fue definido como un promedio `\(N^{-1}\sum_i q(\theta)\)`


---

# Distribución asintótica de estimadores M

- Consideremos `\(\hat{\theta}\)` que resuleve `\(\frac{\partial Q_N(\theta)}{\partial \theta}\Bigg|_{\hat{\theta}}=0\)`

- Realicemos una proximación exacta de primer orden alrededor de `\(\theta_0\)`:

`$$\frac{\partial Q_N(\theta)}{\partial \theta}\Bigg|_{\hat{\theta}}=\frac{\partial Q_N{\theta}}{\partial \theta}\Bigg|_{\theta_0}+\frac{\partial^2Q_N(\theta)}{\partial \theta \theta'}\Bigg|_{\theta^+}(\hat{\theta}-\theta_0)$$`

donde `\(\theta^+\)` es un valor desconocido de `\(\theta\)` entre `\(\hat{\theta}\)` y `\(\theta_0\)`

- Por la condición de primer orden, el lado derecho es igual a cero

`$$\frac{\partial Q_N{\theta}}{\partial \theta}\Bigg|_{\theta_0}+\frac{\partial^2Q_N(\theta)}{\partial \theta \theta'}\Bigg|_{\theta^+}(\hat{\theta}-\theta_0)=0$$`
---

# Distribución asintótica de estimadores M

- Resolviendo para `\((\hat{\theta}-\theta_0)\)` y reescalando por `\(\sqrt{N}\)`:

`$$\sqrt{N}(\hat{\theta}-\theta_0)=-\left(\frac{\partial^2Q_N(\theta)}{\partial \theta\theta'}\right)^{-1}\sqrt{N} \frac{\partial Q_N{\theta}}{\partial \theta}\Bigg|_{\theta_0}$$`
- Noten que esto se parece a lo que teníamos con MCO

- La tarea es asumir las condiciones para aplicar una LGN al primer término y para aplicar un TLC al segundo término

---

# Distribución asintótica de estimadores M

**Distribución límite del máximo local** (Amemiya, 1985, adaptado por CT, 2005)

- Además de los supuestos para la consistencia del máximo local asumimos:

  1. `\(\partial^2Q_N(\theta)/\partial\theta\partial\theta'\)` existe y es continua en una vecindad abierta convexa de `\(\theta_0\)`
  
  1. `\(\partial^2Q_N(\theta)/\partial\theta\theta'|_{\theta^+}\)` converge en probabilidad a la matriz finita y no singular `\(A_0\)`, para toda secuencia `\(\theta^+\)` tal que `\(\theta^+\xrightarrow{p}\theta_0\)`:

  1. `\(\sqrt{N}\partial Q_N(\theta)/\partial \theta |_{\theta_0}\xrightarrow{d}\mathcal{N}(0,B_0)\)`
  
- Entonces, la distribución límite del estimador extremo es:

`$$\sqrt{N}(\hat{\theta}-\theta_0)\xrightarrow{d}\mathcal{N}(0,A_0^{-1}B_0A_0^{-1})$$`
con `\(A_0=p\lim \partial^2Q_N(\theta)/\partial\theta\partial\theta'|_{\theta_0}\)`, `\(B_0=p\lim\left(N\frac{\partial Q_N(\theta)}{\partial \theta}\frac{\partial Q_N{\theta}}{\partial \theta'}|_{\theta_0}\right)\)` y con `\(\hat{\theta}\)` consistente


---

# Distribución asintótica de estimadores M

- Noten que el resultado de la distribución del estimador M asume que ya se ha mostrado la consistencia

- La distribución es un resultado directo de aplicar el límite normal del producto

---

# Próxima sesión

- Abordaremos la estimación por

  - Máxima verosimilitud
  
  - Mínimos cuadrados no lineales

- Son dos casos particulares de estimadores M


---

class: center, middle

Presentación creada usando el paquete [**xaringan**](https://github.com/yihui/xaringan) en R.

El *chakra* viene de [remark.js](https://remarkjs.com), [**knitr**](http://yihui.org/knitr), y [R Markdown](https://rmarkdown.rstudio.com).

Material de clase en versión preliminar.

**No reproducir, no distribuir, no citar.**
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script src="libs/cols_macro.js"></script>
<script>var slideshow = remark.create({
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": null,
"scroll": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
